# 第2章 神经网络的学习

## 本章导读

第1章介绍了神经网络的基本结构和前向传播过程。但仅有网络结构是不够的，我们还需要让网络“学习”——即从数据中自动调整参数，使得预测越来越准确。

**学习目标**：
- 理解损失函数的作用和选择方法
- 掌握数值微分和梯度计算的原理
- 理解梯度下降法的工作原理
- 能够实现完整的神经网络训练流程

**学习路线**：
```
损失函数 → 数值微分 → 梯度计算 → 梯度下降 → 完整训练
(衡量误差)  (求导方法)  (梯度矩阵)  (参数更新)  (实战应用)
```

**核心问题**：
- 如何衡量模型的好坏？→ 损失函数
- 如何找到最优参数？→ 梯度下降
- 如何高效计算梯度？→ 数值微分/反向传播

---

## 2.1 损失函数

损失函数（Loss Function）是衡量神经网络预测值与真实值之间差距的指标，是神经网络学习的核心。通过最小化损失函数，网络可以不断调整参数，提高预测精度。

### 2.1.1 常见损失函数

损失函数的选择直接影响模型的训练效果和收敛速度。以下是几种常见的损失函数：

| 损失函数 | 适用任务 | 特点 |
|---------|---------|------|
| 均方误差（MSE） | 回归 | 对离群点敏感 |
| 平均绝对误差（MAE） | 回归 | 对离群点鲁棒 |
| 交叉熵损失 | 分类 | 适合概率输出 |
| Hinge Loss | 分类 | SVM常用 |

**选择原则**：
- 回归问题：优先考虑 MSE 或 MAE
- 分类问题：优先考虑交叉熵损失
- 特殊需求：根据数据分布和任务特点选择

### 2.1.2 分类任务损失函数

分类任务的目标是将输入数据划分到不同的类别中。

#### 交叉熵损失（Cross-Entropy Loss）

交叉熵损失是分类任务中最常用的损失函数，用于衡量预测概率分布与真实分布之间的差异。

**1）二分类任务损失函数**

二分类任务常用二元交叉熵损失函数（Binary Cross-Entropy Loss）。

$$
L = -(1/n) \sum_{i} (y_i \cdot \log(\hat{y}_i) + (1-y_i) \cdot \log(1-\hat{y}_i))
$$

其中：
- **yᵢ**：为真实值（通常为 0 或 1）
- **ŷᵢ**：为预测值（表示样本 i 为 1 的概率）

**2）多分类任务损失函数**

多分类任务常用多类交叉熵损失函数（Categorical Cross-Entropy Loss）。它是对每个类别的预测概率与真实标签之间差异的加权平均。

$$
L = -(1/n) \sum_{i} \sum_{c} y_{i,c} \cdot \log(\hat{y}_{i,c})
$$

其中：
- **n**：样本数量
- **c**：类别索引
- **yᵢ,c**：样本 i 在类别 c 上的真实标签（one-hot 编码，正确类别为 1，其他为 0）
- **ŷᵢ,c**：样本 i 在类别 c 上的预测概率

**代码实现**（来自 `common/functions.py`）：
```python
# 交叉熵误差
def cross_entropy(y, t):
    # 将y转为二维
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
    # 将t转换为顺序编码（类别标签）
    if t.size == y.size:
        t = t.argmax(axis=1)
    n = y.shape[0]
    return -np.sum(np.log(y[range(n), t] + 1e-10)) / n
```

**代码说明**：
- 支持单样本和批量样本输入
- 支持 one-hot 编码和类别标签两种格式
- 添加 `1e-10` 防止 `log(0)` 导致的数值不稳定

**特点**：
- 预测越接近真实值，损失越小
- 对错误预测惩罚较大
- 与Softmax配合使用效果最佳

### 2.1.3 回归任务损失函数

回归任务的目标是预测连续数值。

#### 均方误差（Mean Squared Error, MSE）

**定义**：
$$
MSE = (1/n) \sum_{i} (y_i - \hat{y}_i)^2
$$

其中：
- yᵢ：真实值
- ŷᵢ：预测值
- n：样本数量

**代码实现**（来自 `common/functions.py`）：
```python
def mean_square_error(y_true, y_pred):
    return 0.5*np.sum((y_true - y_pred)**2)
```

**代码说明**：
- `y_true`：真实标签值
- `y_pred`：神经网络的预测值
- 乘以 0.5 是为了求导时约去系数，简化梯度计算
- 使用 `np.sum` 对所有样本的误差求和

**特点**：
- 对离群点敏感（平方放大误差）
- 可微分，便于优化
- 梯度随误差线性变化

#### 平均绝对误差（Mean Absolute Error, MAE）

**定义**：
$$
MAE = (1/n) \sum_{i} |y_i - \hat{y}_i|
$$

**特点**：
- 对离群点更鲁棒
- 在零点处不可微

#### Smooth L1（平滑 L1）

Smooth L1 损失函数结合了 MSE 和 MAE 的优点，在小误差时使用二次函数，在大误差时使用绝对值函数。

**定义**：
$$
Smooth\ L1 = \begin{cases}
(1/2)(y_i - \hat{y}_i)^2, & \text{当 } |y_i - \hat{y}_i| < 1 \\
|y_i - \hat{y}_i| - 1/2, & \text{当 } |y_i - \hat{y}_i| \geq 1
\end{cases}
$$

其中：
- **yᵢ**：真实值
- **ŷᵢ**：预测值

**特点**：
- 小误差时（< 1）：使用 MSE，梯度平滑，收敛稳定
- 大误差时（≥ 1）：使用 MAE，对离群点鲁棒
- 处处可微，适合梯度下降优化
- 广泛用于目标检测（如 Faster R-CNN）

#### MSE vs MAE 对比

| 特性 | MSE | MAE |
|-----|-----|-----|
| 离群点敏感度 | 高 | 低 |
| 可微性 | 处处可微 | 零点不可微 |
| 梯度特点 | 随误差变化 | 恒定 |
| 收敛速度 | 较快 | 较慢 |

---

## 2.2 数值微分

数值微分是通过数值方法近似计算函数导数的技术，是理解神经网络梯度计算的基础。

### 2.2.1 导数和数值微分

#### 导数的定义

在进入数值微分之前，我们需要理解导数的本质。

**数学定义**：
导数表示函数在某一点的瞬时变化率：

$$
f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}
$$

**直观理解**：
- **几何意义**：曲线在该点的切线斜率
- **物理意义**：描述了“变化率”——x 的微小变化引起 f(x) 的变化程度

**导数的含义**：
- **导数为正**：函数递增，增大 x 会增大 f(x)
- **导数为负**：函数递减，增大 x 会减小 f(x)
- **导数绝对值大**：变化快，x 的微小变化导致 f(x) 的大幅变化

**在神经网络中的意义**：
- 导数告诉我们“参数如何影响损失函数”
- 正导数：减小该参数可以降低损失
- 负导数：增大该参数可以降低损失
- 这就是梯度下降法的数学基础

#### 数值微分

由于计算机无法处理无穷小量，我们使用有限差分来近似导数：

**前向差分**：
$$
f'(x) \approx \frac{f(x+h) - f(x)}{h}
$$

**中心差分**（推荐，精度更高）：
$$
f'(x) \approx \frac{f(x+h) - f(x-h)}{2h}
$$

**代码实现**（来自 `common/gradient.py`）：
```python
# 数值微分求导
def numerical_diff(f, x):
    h = 1e-4
    return (f(x + h) - f(x - h )) / (2 * h)
```

**应用示例：绘制函数切线**（来自 `ch03_train/1_tangent_line.py`）：
```python
import numpy as np
import matplotlib.pyplot as plt
from common.gradient import numerical_diff

# 原函数 y = 0.01x² + 0.1x
def f(x):
    return 0.01*x**2 + 0.1*x

# 切线方程函数：返回在指定点的切线函数
def tangent_line(f, x):
    # 计算 x 处切线的斜率（利用数值微分）
    y = f(x)
    a = numerical_diff(f, x)
    print("斜率为", a)
    # 计算截距: b = y - ax
    b = y - a*x
    return lambda x: a*x + b

# 定义画图范围
x_range = np.arange(0.0, 20.0, 0.1)
y_range = f(x_range)

# 计算 x=5 的切线方程
f_line = tangent_line(f, x=5)
y_line = f_line(x_range)

plt.plot(x_range, y_range)  # 原函数曲线
plt.plot(x_range, y_line)   # 切线
plt.show()
```

**代码说明**：
- 使用中心差分公式计算导数（斜率）
- h = 1e-4 是常用折中值，平衡截断误差和舍入误差
- 切线方程：y = ax + b，其中 a 是斜率，b 是截距

**注意事项**：
- h 的选择：通常取 1e-4 到 1e-7
- h 太大：截断误差大
- h 太小：舍入误差大

### 2.2.2 偏导数

对于多变量函数，偏导数表示函数关于某一个变量的变化率，其他变量保持不变。

**定义**：
对于函数 f(x₁, x₂, ..., xₙ)，关于 xᵢ 的偏导数为：

$$
\frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1,...,x_i+h,...,x_n) - f(x_1,...,x_i,...,x_n)}{h}
$$

**示例**：
对于 f(x₀, x₁) = x₀² + x₁²

$$
\frac{\partial f}{\partial x_0} = 2x_0
$$

$$
\frac{\partial f}{\partial x_1} = 2x_1
$$

**代码实现**（来自 `common/gradient.py`）：
```python
# 数值微分求梯度（单样本）
def _numerical_gradient(f, x):
    h = 1e-4
    grad = np.zeros_like(x)
    # 遍历 x 的特征
    for i in range(x.size):
        tmp = x[i]
        x[i] = tmp + h
        fxh1 = f(x)
        x[i] = tmp - h
        fxh2 = f(x)
        grad[i] = (fxh1 - fxh2) / (2 * h)
        x[i] = tmp
    return grad

# 数值梯度计算（支持矩阵输入）
# 用于计算损失函数对参数的梯度，是梯度下降算法的基础
# 参数:
#   f: 损失函数，接受参数并返回损失值
#   X: 输入参数，可以是一维数组（单样本）或二维矩阵（多样本）
# 返回:
#   与 X 同形状的梯度矩阵
def numerical_gradient(f, X):
    # 判断输入维度，分别处理单样本和多样本情况
    if X.ndim == 1:
        # 一维数组（单样本）：直接调用底层梯度计算函数
        return _numerical_gradient(f, X)
    else:
        # 二维矩阵（多样本）：创建同形状的零矩阵存储梯度
        grad = np.zeros_like(X)
        # 遍历矩阵的每一行（每个样本）
        for i, x in enumerate(X):
            grad[i] = _numerical_gradient(f, x)
        return grad
```

**代码说明**：
- 偏导数计算时，其他变量保持不变
- 逐个变量应用中心差分公式
- 计算完后必须还原原始值，否则影响后续计算
- 支持单样本（一维）和多样本（二维）输入

### 2.2.3 梯度

梯度是由所有偏导数组成的向量，指向函数值增加最快的方向。

**定义**：
$$
\nabla f = \left(\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ..., \frac{\partial f}{\partial x_n}\right)
$$

**梯度的性质**：
1. **方向**：指向函数值上升最快的方向
2. **大小**：表示最大变化率
3. **负梯度**：指向函数值下降最快的方向

**代码实现**（与偏导数计算相同，梯度就是所有偏导数组成的向量）：
```python
def compute_gradient(f, x):
    """
    计算梯度向量
    
    参数:
        f: 多元函数
        x: 计算梯度的点
    
    返回:
        梯度向量 ∇f = (∂f/∂x₁, ∂f/∂x₂, ..., ∂f/∂xₙ)
    """
    return numerical_gradient_1d(f, x)  # 梯度就是所有偏导数组成的向量

# 示例：对 f(x,y) = x² + y² 计算梯度
point = np.array([3.0, 4.0])
grad = compute_gradient(function_2, point)
print(f"点 {point} 处的梯度: {grad}")  # 输出: [6. 8.]
print(f"梯度大小: {np.linalg.norm(grad):.2f}")  # 输出: 10.00
```

**几何意义**：
- 在等高线图中，梯度垂直于等高线
- 梯度的模表示函数变化的剧烈程度

---

## 2.3 神经网络的梯度计算

在神经网络的学习中，梯度的计算非常重要。神经网络中的梯度，指的就是损失函数关于权重参数的梯度。

### 2.3.1 权重参数的梯度

我们以一个单层的简单网络为例，形状为 2×3，权重参数为 W，损失函数记为 L。那么它的权重参数和梯度为：

**权重矩阵 W**：
$$
W = \begin{bmatrix} w_{11} & w_{12} & w_{13} \\ w_{21} & w_{22} & w_{23} \end{bmatrix}
$$

**梯度矩阵 ∂L/∂W**：
$$
\frac{\partial L}{\partial W} = \begin{bmatrix} \frac{\partial L}{\partial w_{11}} & \frac{\partial L}{\partial w_{12}} & \frac{\partial L}{\partial w_{13}} \\ \frac{\partial L}{\partial w_{21}} & \frac{\partial L}{\partial w_{22}} & \frac{\partial L}{\partial w_{23}} \end{bmatrix}
$$

**重要说明**：
- 梯度 ∂L/∂W 也是一个 2×3 的矩阵，与权重矩阵形状相同
- 其中各个元素由 L 关于 W 中各元素的偏导数构成
- 例如，∂L/∂w₁₁ 表示当 w₁₁ 稍微变化时，损失函数 L 会发生多大变化

### 2.3.2 梯度计算方法

计算神经网络梯度有两种主要方法：

**1）数值微分法**
- **原理**：使用有限差分近似导数
- **优点**：实现简单，可用于验证
- **缺点**：计算量大，精度有限

**2）解析法（反向传播）**
- **原理**：利用链式法则计算梯度
- **优点**：计算效率高，精度高
- **缺点**：实现较复杂

### 2.3.3 神经网络梯度的数值计算

通过一个简单的神经网络示例，演示梯度计算的完整流程。

**代码实现**（来自 `ch03_train/2_simple_net_grad.py`）：
```python
import numpy as np
from common.functions import softmax, cross_entropy
from common.gradient import numerical_gradient

# SimpleNet: 最简单的神经网络，用于演示梯度计算流程
# 网络结构: 输入层(2个神经元) -> 输出层(3个神经元)
class SimpleNet:
    def __init__(self):
        # 初始化权重矩阵 W，形状为 (2, 3)
        # 2: 输入特征数，3: 输出类别数
        self.W = np.random.randn(2, 3)
    
    def forward(self, x):
        # 前向传播：计算预测概率分布
        a = x @ self.W    # 矩阵乘法：计算加权和
        y = softmax(a)    # 转换为概率分布
        return y
    
    def loss(self, x, t):
        # 计算损失值：预测与真实标签的交叉熵
        y = self.forward(x)
        loss = cross_entropy(y, t)
        return loss

# 主流程：完整的梯度计算示例
if __name__ == '__main__':
    # 第1步：准备数据
    x = np.array([0.6, 0.9])   # 输入数据：2个特征
    t = np.array([0, 0, 1])    # 真实标签：one-hot编码，真实类别为2
    
    # 第2步：创建神经网络
    net = SimpleNet()
    
    # 第3步：计算梯度
    # 将损失函数包装成只关于 W 的函数
    f = lambda w: net.loss(x, t)
    
    # 调用数值梯度计算
    gradw = numerical_gradient(f, net.W)
    print(gradw)
```

**完整计算流程示例**（假设权重为 W = [[0.5,-0.3,0.8],[0.2,0.7,-0.4]]）：

```
【前向传播】
输入: x = [0.6, 0.9]
权重: W = [[ 0.5, -0.3,  0.8],
           [ 0.2,  0.7, -0.4]]

a = x @ W
  = [0.6*0.5 + 0.9*0.2,  0.6*(-0.3) + 0.9*0.7,  0.6*0.8 + 0.9*(-0.4)]
  = [0.48,               0.45,                  0.12]

y = softmax([0.48, 0.45, 0.12])
  = [0.370, 0.359, 0.271]  # 三个类别的预测概率

【计算损失】
真实标签: t = [0, 0, 1] → 真实类别是2
类别2的预测概率: y[2] = 0.271
loss = -log(0.271) = 1.306

【计算梯度】以 W[0,0] 为例：
h = 0.0001

W[0,0] = 0.5 + 0.0001 = 0.5001 → 重新前向传播 → loss1 = 1.3058
W[0,0] = 0.5 - 0.0001 = 0.4999 → 重新前向传播 → loss2 = 1.3062

grad[0,0] = (loss1 - loss2) / (2h) = (1.3058 - 1.3062) / 0.0002 = -0.02

意义：W[0,0]增加时，损失减小，所以梯度为负
梯度下降时：W[0,0] = W[0,0] - lr * grad[0,0]
由于 grad 为负，所以 W[0,0] 会增大，损失继续减小
```

**代码说明**：
- SimpleNet 是最简单的神经网络，只有一层权重
- `forward` 方法执行前向传播，计算预测概率
- `loss` 方法计算交叉熵损失
- `numerical_gradient` 计算损失函数对权重的梯度
- 梯度矩阵与权重矩阵形状相同

### 2.3.4 梯度检验

用数值梯度验证解析梯度的正确性：

$$
相对误差 = \frac{|数值梯度 - 解析梯度|}{\max(|数值梯度|, |解析梯度|)}
$$

**判断标准**：
- 相对误差 < 1e-7：梯度计算正确
- 相对误差 > 1e-5：可能存在问题

---

## 2.4 随机梯度下降法（SGD）

### 2.4.1 梯度下降法

梯度下降法是最基本的优化算法，通过沿负梯度方向迭代更新参数来最小化损失函数。

**更新公式**：
$$
\theta = \theta - \eta \cdot \nabla L(\theta)
$$

其中：
- θ：模型参数
- η：学习率（learning rate）
- ∇L(θ)：损失函数关于参数的梯度

**梯度下降的变体**：

| 方法 | 描述 | 特点 |
|-----|------|------|
| 批量梯度下降（BGD） | 使用全部数据计算梯度 | 稳定但慢 |
| 随机梯度下降（SGD） | 使用单个样本计算梯度 | 快但不稳定 |
| 小批量梯度下降（Mini-batch） | 使用一小批数据 | 平衡稳定性和速度 |

**代码实现**（来自 `ch03_train/3_gradient_descent.py`）：
```python
import numpy as np
from common.gradient import numerical_gradient
import matplotlib.pyplot as plt

# 定义梯度下降法的函数
def gradient_descent(f, init_x, lr=0.01, step_num=100):
    """
    梯度下降法求函数最小值
    
    参数:
        f: 目标函数（要最小化的函数）
        init_x: 初始参数值
        lr: 学习率
        step_num: 迭代次数
    
    返回:
        x: 优化后的参数值
        x_history: 优化过程中的历史点
    """
    x = init_x
    x_history = []  # 记录优化过程
    
    for i in range(step_num):
        x_history.append(x.copy())
        grad = numerical_gradient(f, x)  # 计算梯度
        x -= lr * grad  # 沿负梯度方向更新
    
    return x, np.array(x_history)

# 定义目标函数 f(x) = x₀² + x₁²
def f(x):
    return x[0]**2 + x[1]**2

if __name__ == '__main__':
    # 定义初始值
    init_x = np.array([-3.0, 4.0])
    # 定义超参数
    lr = 0.9
    num_iter = 2000
    
    # 梯度下降法
    x, x_history = gradient_descent(f, init_x, lr=lr, step_num=num_iter)
    print("最小值点", x)
    
    # 画图：显示优化过程
    plt.plot([-5,5],[0,0],'--b')  # x轴
    plt.plot([0,0],[-5,5],'--b')  # y轴
    plt.plot(x_history[:, 0], x_history[:, 1], "o")  # 优化路径
    plt.xlim([-3.5,3.5])
    plt.ylim([-4.5,4.5])
    plt.xlabel("x0")
    plt.ylabel("x1")
    plt.show()
```

**代码说明**：
- 每次迭代计算梯度，然后沿负梯度方向更新参数
- 学习率 lr=0.9 控制每步移动的大小
- `x_history` 记录优化过程，可用于可视化
- 最终收敛到最小值点 (0, 0) 附近

### 2.4.2 模型训练相关概念

在神经网络训练中，三个核心概念是 Epoch、Batch Size 和 Iteration。理解它们之间的关系对于设置训练参数至关重要。

#### 1）Epoch（轮次）

**定义**：1 个 Epoch 表示模型完整遍历了一次整个训练数据集的过程。

**示例**：训练 10 个 Epoch 表示模型将整个数据集反复学习 10 次。

```
训练过程：Epoch 1 → Epoch 2 → ... → Epoch N
```

**重要说明**：
- 模型需要多次遍历数据集（多个 Epoch）才能逐步学习数据中的模式
- 单次遍历数据集（1 个 Epoch）通常不足以让模型收敛
- 多次遍历可以逐步优化模型参数

#### 2）Batch Size（批量大小）

**定义**：Batch Size 是每次训练时输入的样本数量。

**示例**：Batch Size=32 表示每次用 32 个样本计算一次梯度并更新模型参数。

**选择建议**：
- **小批量**：小批量数据计算梯度比单样本（Batch Size=1）更稳定
- **大批量**：比全批量（Batch Size=全体数据）更高效
- **常用值**：32, 64, 128, 256
- **内存限制**：根据GPU显存调整
- **收敛性**：较小的 Batch Size 可能带来更多噪声，有助于模型泛化

#### 3）Iteration（迭代次数）

**定义**：一次 Iteration 表示完成一个 Batch 数据的正向传播（预测）和反向传播（更新参数）的过程。

**计算公式**：
$$
迭代次数 = 训练样本数 / Batch\ Size
$$

**示例**：
- 数据集现有 2000 个样本，对其训练 10 个 Epoch，选择 Batch Size=64：
  - **每个 Epoch 的迭代次数** = 2000 / 64 ≈ 32 次
  - **总迭代次数** = 32 × 10 = 320 次

**三者关系总结**：
$$
1\ 个\ Epoch = (训练样本数 / Batch\ Size) 个\ Iteration
$$

$$
总\ Iteration\ 数 = Epoch\ 数 \times (训练样本数 / Batch\ Size)
$$

#### 学习率（Learning Rate）

学习率决定了参数更新的步长。

**学习率的影响**：
- 太大：可能跳过最优解，导致震荡或发散
- 太小：收敛速度慢
- 合适：稳定收敛到最优解

**学习率调整策略**：
1. 固定学习率
2. 学习率衰减（Step Decay, Exponential Decay）
3. 自适应学习率（Adam, RMSprop）

### 2.4.3 SGD

随机梯度下降（Stochastic Gradient Descent）是最基础的优化算法。

**算法流程**：
```
1. 初始化参数 θ
2. 重复以下步骤直到收敛：
   a. 随机选择一个（或一批）样本
   b. 计算损失函数关于参数的梯度
   c. 更新参数：θ = θ - η·∇L(θ)
```

**代码实现**：
```python
class SGD:
    """
    随机梯度下降优化器
    
    参数:
        lr: 学习率 (learning rate)
    """
    def __init__(self, lr=0.01):
        self.lr = lr
    
    def update(self, params, grads):
        """
        更新参数
        
        参数:
            params: 参数字典，如 {'W1': ..., 'b1': ..., 'W2': ..., 'b2': ...}
            grads: 梯度字典，与 params 结构相同
        """
        for key in params.keys():
            # 更新公式：θ = θ - η·∇L(θ)
            params[key] -= self.lr * grads[key]

# 使用示例
optimizer = SGD(lr=0.01)
optimizer.update(network.params, grads)  # 一次参数更新
```

**代码说明**：
- 将优化器封装为类，便于管理和替换
- `update` 方法直接修改传入的 params 字典
- 简单易懂，但可以扩展为 Momentum、Adam 等更复杂的优化器

**SGD的优缺点**：

| 优点 | 缺点 |
|-----|------|
| 实现简单 | 学习率难以选择 |
| 计算效率高 | 容易陷入局部最优 |
| 在线学习 | 在鞍点处收敛慢 |
| 有助于跳出局部最优 | 震荡现象 |

**SGD的改进版本**：
1. **动量（Momentum）**：引入历史梯度信息
2. **Nesterov动量**：预测下一步位置后再计算梯度
3. **AdaGrad**：自适应调整每个参数的学习率
4. **RMSprop**：解决AdaGrad学习率衰减过快问题
5. **Adam**：结合动量和自适应学习率

---

## 2.5 综合代码实现

本节将整合以上所有概念，实现一个完整的神经网络训练流程。

### 训练流程概览

```
1. 数据准备
   ↓
2. 网络初始化
   ↓
3. 前向传播（计算预测值）
   ↓
4. 计算损失（损失函数）
   ↓
5. 反向传播（计算梯度）
   ↓
6. 参数更新（SGD）
   ↓
7. 重复步骤3-6直到收敛
```

### 完整实现

#### TwoLayerNet 类（来自 `ch03_train/two_layer_net.py`）

```python
import numpy as np
from common.functions import sigmoid, softmax, cross_entropy
from common.gradient import numerical_gradient

class TwoLayerNet:
    """
    两层神经网络类
    
    网络结构:
        输入层 (input_size) → 隐藏层 (hidden_size) → 输出层 (output_size)
    """
    
    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):
        """
        初始化网络参数
        
        参数:
            input_size: 输入层大小（特征数）
            hidden_size: 隐藏层神经元数
            output_size: 输出层大小（类别数）
            weight_init_std: 权重初始化标准差
        """
        self.params = {}
        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)
        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b1'] = np.zeros((1, hidden_size))
        self.params['b2'] = np.zeros((1, output_size))

    # 前向传播
    # x @ W1 等价于 np.dot(x, W1)，是Python 3.5+的矩阵乘法运算符
    def forward(self, x):
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']
        a1 = x @ W1 + b1       # (batch, 784) @ (784, 50) -> (batch, 50)
        z1 = sigmoid(a1)
        a2 = z1 @ W2 + b2      # (batch, 50) @ (50, 10) -> (batch, 10)
        y = softmax(a2) 
        return y

    # 计算损失
    def loss(self, x, t):
        y = self.forward(x)
        loss = cross_entropy(y, t)
        return loss

    # 计算准确度
    def accuracy(self, x, t):
        y = self.forward(x)
        # 根据最大概率得到分类号
        y = np.argmax(y, axis=1)
        # 与正确的标签对比，获得准确率
        accuracy = np.sum(y==t) / x.shape[0]
        return accuracy

    # 计算梯度
    # 注意：lambda 参数名用 _ 而非 x，避免覆盖外部输入数据 x
    # numerical_gradient 会直接修改 self.params 中的值来计算数值梯度
    def numerical_gradient(self, x, t):
        loss_f = lambda _: self.loss(x, t)  # _ 是占位符，实际用的是被扰动的 self.params
        grads = {}
        grads['W1'] = numerical_gradient(loss_f, self.params['W1'])
        grads['W2'] = numerical_gradient(loss_f, self.params['W2'])
        grads['b1'] = numerical_gradient(loss_f, self.params['b1'])
        grads['b2'] = numerical_gradient(loss_f, self.params['b2'])
        return grads
```

**代码说明**：
- **参数存储**：使用字典 `params` 统一管理权重和偏置
- **前向传播**：`forward` 方法使用 `@` 运算符进行矩阵乘法
- **梯度计算**：`numerical_gradient` 计算所有参数的梯度
- **注意事项**：lambda 中用 `_` 作占位符，避免变量名冲突 

#### 数据加载模块（来自 `common/load_data.py`）

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

def get_data():
    """
    加载并预处理手写数字数据集
    
    返回:
        x_train, y_train, x_test, y_test
    """
    # 1. 从文件加载数据集
    data = pd.read_csv("../data/train.csv")
    # 2. 划分数据集
    X = data.drop(labels="label", axis=1)
    y = data["label"]
    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    # 3. 特征工程: 归一化
    scaler = MinMaxScaler()
    x_train = scaler.fit_transform(x_train)
    x_test = scaler.transform(x_test)
    # 4. 数据转换为ndarray
    y_train = y_train.values
    y_test = y_test.values
    return x_train, y_train, x_test, y_test
```

#### 完整训练代码（来自 `ch03_train/4_digit_recognizer_nn_train.py`）

```python
import pandas as pd
from common.load_data import get_data
from two_layer_net import TwoLayerNet

# 1. 加载数据
x_train, y_train, x_test, y_test = get_data()

# 2. 初始化模型
model = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)

# 3. 设置超参数
learning_rate = 0.1
num_epochs = 10
batch_size = 100
train_size = x_train.shape[0]
iter_per_epoch = train_size // batch_size
iter_num = num_epochs * iter_per_epoch

train_loss_list = []
train_acc_list = []
test_acc_list = []

# 4. 循环迭代，用梯度下降法训练模型
for i in range(iter_num):
    # 4.1 随机选取批量数据
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = y_train[batch_mask]
    
    # 4.2 计算梯度
    grad = model.numerical_gradient(x_batch, t_batch)
    
    # 4.3 更新参数
    for key in ('W1', 'W2', 'b1', 'b2'):
        model.params[key] -= learning_rate * grad[key]
    
    # 4.4 保存当前训练损失
    train_loss_list.append(model.loss(x_batch, t_batch))
    
    # 4.5 每个epoch结束时计算准确度
    if i % iter_per_epoch == 0:
        train_acc = model.accuracy(x_train, y_train)
        test_acc = model.accuracy(x_test, y_test)
        print("train acc, test acc | " + str(train_acc) + ", " + str(test_acc))
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)

# 5. 画图
import matplotlib.pyplot as plt
x = np.arange(len(train_acc_list))
plt.plot(x, train_acc_list, label='train acc')
plt.plot(x, test_acc_list, label='test acc')
plt.legend(loc='best')
plt.show()
```

**代码说明**：
1. **数据加载**：使用 `get_data()` 加载并预处理数据
2. **模型初始化**：784(输入) → 50(隐藏) → 10(输出)
3. **超参数设置**：学习率=0.1，10个Epoch，Batch=100
4. **训练循环**：
   - 随机抽取mini-batch
   - 计算梯度
   - SGD更新参数
   - 记录损失和准确率
5. **可视化**：绘制训练和测试准确率曲线

### 训练技巧总结

1. **数据预处理**：
   - 特征归一化/标准化
   - 数据增强
   - 打乱训练数据顺序

2. **参数初始化**：
   - Xavier初始化
   - He初始化
   - 避免全零初始化

3. **学习率设置**：
   - 从较大值开始尝试
   - 观察损失曲线调整
   - 使用学习率调度器

4. **防止过拟合**：
   - Dropout
   - L2正则化
   - Early Stopping
   - 数据增强

5. **监控训练过程**：
   - 记录训练/验证损失
   - 可视化学习曲线
   - 定期保存模型检查点

---

## 总结

本章介绍了神经网络学习的核心概念：

### 理论基础

1. **损失函数**：
   - 分类任务：交叉熵损失
   - 回归任务：MSE、MAE
   - 损失函数的选择影响训练效果

2. **数值微分**：
   - 导数和偏导数的数值计算
   - 梯度的概念和几何意义
   - 中心差分法提高精度

3. **梯度计算**：
   - 神经网络梯度的数值计算方法
   - 梯度检验确保实现正确性

4. **优化算法**：
   - 梯度下降法的原理
   - Epoch、Batch Size、Iteration的概念
   - SGD及其改进版本

### 关键收获

✅ 理解损失函数的作用和选择原则  
✅ 掌握数值微分和梯度计算方法  
✅ 理解梯度下降法的工作原理  
✅ 掌握训练相关的核心概念（Epoch、Batch、学习率）  
✅ 了解SGD优化器及其改进版本  

### 后续学习方向

1. **反向传播算法**：利用链式法则高效计算梯度
2. **高级优化器**：Adam、RMSprop等自适应优化器
3. **正则化技术**：防止过拟合的各种方法
4. **学习率调度**：动态调整学习率的策略
5. **分布式训练**：大规模数据的并行训练

### 实践建议

**初学者常见问题及解决方案**：

1. **损失不下降**：
   - 检查学习率是否合适（建议 0.001-0.1）
   - 确认梯度计算是否正确
   - 尝试调整 Batch Size

2. **训练过慢**：
   - 使用更大的 Batch Size
   - 考虑使用 GPU 加速
   - 减小网络规模或减少 Epoch 数

3. **数值不稳定（NaN）**：
   - 降低学习率
   - 检查数据是否归一化
   - 添加梯度裁剪（Gradient Clipping）

4. **记不住概念**：
   - Epoch = 全部数据过一遍
   - Batch = 一次更新用多少样本
   - Iteration = 一个 Epoch 里更新多少次
   - 关系：Iteration = 样本数 / Batch Size

**动手实践建议**：
- 修改学习率，观察训练曲线变化
- 尝试不同的 Batch Size，比较收敛速度
- 实现梯度检验，确保梯度计算正确
- 可视化损失曲线，分析训练过程

# 第 2 章 神经网络的学习

## 2.1 损失函数

损失函数（Loss Function）是衡量神经网络预测值与真实值之间差距的指标，是神经网络学习的核心。通过最小化损失函数，网络可以不断调整参数，提高预测精度。

### 2.1.1 常见损失函数

损失函数的选择直接影响模型的训练效果和收敛速度。以下是几种常见的损失函数：

| 损失函数 | 适用任务 | 特点 |
|---------|---------|------|
| 均方误差（MSE） | 回归 | 对离群点敏感 |
| 平均绝对误差（MAE） | 回归 | 对离群点鲁棒 |
| 交叉熵损失 | 分类 | 适合概率输出 |
| Hinge Loss | 分类 | SVM常用 |

**选择原则**：
- 回归问题：优先考虑 MSE 或 MAE
- 分类问题：优先考虑交叉熵损失
- 特殊需求：根据数据分布和任务特点选择

### 2.1.2 分类任务损失函数

分类任务的目标是将输入数据划分到不同的类别中。

#### 交叉熵损失（Cross-Entropy Loss）

交叉熵损失是分类任务中最常用的损失函数，用于衡量预测概率分布与真实分布之间的差异。

**1）二分类任务损失函数**

二分类任务常用二元交叉熵损失函数（Binary Cross-Entropy Loss）。

```
L = -(1/n) Σᵢ (yᵢ · log(ŷᵢ) + (1-yᵢ) · log(1-ŷᵢ))
```

其中：
- **yᵢ**：为真实值（通常为 0 或 1）
- **ŷᵢ**：为预测值（表示样本 i 为 1 的概率）

**2）多分类任务损失函数**

多分类任务常用多类交叉熵损失函数（Categorical Cross-Entropy Loss）。它是对每个类别的预测概率与真实标签之间差异的加权平均。

```
L = -(1/n) Σᵢ Σc yᵢ,c · log(ŷᵢ,c)
```

其中：
- **n**：样本数量
- **c**：类别索引
- **yᵢ,c**：样本 i 在类别 c 上的真实标签（one-hot 编码，正确类别为 1，其他为 0）
- **ŷᵢ,c**：样本 i 在类别 c 上的预测概率

**代码实现**（来自 `common/functions.py`）：
```python
# 交叉熵误差
def cross_entropy(y, t):
    # 将y转为二维
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
    # 将t转换为顺序编码（类别标签）
    if t.size == y.size:
        t = t.argmax(axis=1)
    n = y.shape[0]
    return -np.sum(np.log(y[range(n), t] + 1e-10)) / n
```

**代码说明**：
- 支持单样本和批量样本输入
- 支持 one-hot 编码和类别标签两种格式
- 添加 `1e-10` 防止 `log(0)` 导致的数值不稳定

**特点**：
- 预测越接近真实值，损失越小
- 对错误预测惩罚较大
- 与Softmax配合使用效果最佳

### 2.1.3 回归任务损失函数

回归任务的目标是预测连续数值。

#### 均方误差（Mean Squared Error, MSE）

**定义**：
```
MSE = (1/n) Σᵢ (yᵢ - ŷᵢ)²
```

其中：
- yᵢ：真实值
- ŷᵢ：预测值
- n：样本数量

**代码实现**（来自 `common/functions.py`）：
```python
def mean_square_error(y_true, y_pred):
    return 0.5*np.sum((y_true - y_pred)**2)
```

**代码说明**：
- `y_true`：真实标签值
- `y_pred`：神经网络的预测值
- 乘以 0.5 是为了求导时约去系数，简化梯度计算
- 使用 `np.sum` 对所有样本的误差求和

**特点**：
- 对离群点敏感（平方放大误差）
- 可微分，便于优化
- 梯度随误差线性变化

#### 平均绝对误差（Mean Absolute Error, MAE）

**定义**：
```
MAE = (1/n) Σᵢ |yᵢ - ŷᵢ|
```

**特点**：
- 对离群点更鲁棒
- 在零点处不可微

#### Smooth L1（平滑 L1）

Smooth L1 损失函数结合了 MSE 和 MAE 的优点，在小误差时使用二次函数，在大误差时使用绝对值函数。

**定义**：
```
Smooth L1 = 
    (1/2)(yᵢ - ŷᵢ)²      , 当 |yᵢ - ŷᵢ| < 1
    |yᵢ - ŷᵢ| - 1/2   , 当 |yᵢ - ŷᵢ| ≥ 1
```

其中：
- **yᵢ**：真实值
- **ŷᵢ**：预测值

**特点**：
- 小误差时（< 1）：使用 MSE，梯度平滑，收敛稳定
- 大误差时（≥ 1）：使用 MAE，对离群点鲁棒
- 处处可微，适合梯度下降优化
- 广泛用于目标检测（如 Faster R-CNN）

#### MSE vs MAE 对比

| 特性 | MSE | MAE |
|-----|-----|-----|
| 离群点敏感度 | 高 | 低 |
| 可微性 | 处处可微 | 零点不可微 |
| 梯度特点 | 随误差变化 | 恒定 |
| 收敛速度 | 较快 | 较慢 |

---

## 2.2 数值微分

数值微分是通过数值方法近似计算函数导数的技术，是理解神经网络梯度计算的基础。

### 2.2.1 导数和数值微分

#### 导数的定义

导数表示函数在某一点的瞬时变化率：

```
f'(x) = lim[h→0] (f(x+h) - f(x)) / h
```

#### 数值微分

由于计算机无法处理无穷小量，我们使用有限差分来近似导数：

**前向差分**：
```
f'(x) ≈ (f(x+h) - f(x)) / h
```

**中心差分**（推荐，精度更高）：
```
f'(x) ≈ (f(x+h) - f(x-h)) / 2h
```

**代码实现**（来自 `common/gradient.py`）：
```python
# 数值微分求导
def numerical_diff(f, x):
    h = 1e-4
    return (f(x + h) - f(x - h )) / (2 * h)
```

**应用示例：绘制函数切线**（来自 `ch03_train/1_tangent_line.py`）：
```python
import numpy as np
import matplotlib.pyplot as plt
from common.gradient import numerical_diff

# 原函数 y = 0.01x² + 0.1x
def f(x):
    return 0.01*x**2 + 0.1*x

# 切线方程函数：返回在指定点的切线函数
def tangent_line(f, x):
    # 计算 x 处切线的斜率（利用数值微分）
    y = f(x)
    a = numerical_diff(f, x)
    print("斜率为", a)
    # 计算截距: b = y - ax
    b = y - a*x
    return lambda x: a*x + b

# 定义画图范围
x_range = np.arange(0.0, 20.0, 0.1)
y_range = f(x_range)

# 计算 x=5 的切线方程
f_line = tangent_line(f, x=5)
y_line = f_line(x_range)

plt.plot(x_range, y_range)  # 原函数曲线
plt.plot(x_range, y_line)   # 切线
plt.show()
```

**代码说明**：
- 使用中心差分公式计算导数（斜率）
- h = 1e-4 是常用折中值，平衡截断误差和舍入误差
- 切线方程：y = ax + b，其中 a 是斜率，b 是截距

**注意事项**：
- h 的选择：通常取 1e-4 到 1e-7
- h 太大：截断误差大
- h 太小：舍入误差大

### 2.2.2 偏导数

对于多变量函数，偏导数表示函数关于某一个变量的变化率，其他变量保持不变。

**定义**：
对于函数 f(x₁, x₂, ..., xₙ)，关于 xᵢ 的偏导数为：

```
∂f/∂xᵢ = lim[h→0] (f(x₁,...,xᵢ+h,...,xₙ) - f(x₁,...,xᵢ,...,xₙ)) / h
```

**示例**：
对于 f(x₀, x₁) = x₀² + x₁²

```
∂f/∂x₀ = 2x₀
∂f/∂x₁ = 2x₁
```

**代码实现**（来自 `common/gradient.py`）：
```python
# 数值微分求梯度（单样本）
def _numerical_gradient(f, x):
    h = 1e-4
    grad = np.zeros_like(x)
    # 遍历 x 的特征
    for i in range(x.size):
        tmp = x[i]
        x[i] = tmp + h
        fxh1 = f(x)
        x[i] = tmp - h
        fxh2 = f(x)
        grad[i] = (fxh1 - fxh2) / (2 * h)
        x[i] = tmp
    return grad

# 数值梯度计算（支持矩阵输入）
# 用于计算损失函数对参数的梯度，是梯度下降算法的基础
# 参数:
#   f: 损失函数，接受参数并返回损失值
#   X: 输入参数，可以是一维数组（单样本）或二维矩阵（多样本）
# 返回:
#   与 X 同形状的梯度矩阵
def numerical_gradient(f, X):
    # 判断输入维度，分别处理单样本和多样本情况
    if X.ndim == 1:
        # 一维数组（单样本）：直接调用底层梯度计算函数
        return _numerical_gradient(f, X)
    else:
        # 二维矩阵（多样本）：创建同形状的零矩阵存储梯度
        grad = np.zeros_like(X)
        # 遍历矩阵的每一行（每个样本）
        for i, x in enumerate(X):
            grad[i] = _numerical_gradient(f, x)
        return grad
```

**代码说明**：
- 偏导数计算时，其他变量保持不变
- 逐个变量应用中心差分公式
- 计算完后必须还原原始值，否则影响后续计算
- 支持单样本（一维）和多样本（二维）输入

### 2.2.3 梯度

梯度是由所有偏导数组成的向量，指向函数值增加最快的方向。

**定义**：
```
∇f = (∂f/∂x₁, ∂f/∂x₂, ..., ∂f/∂xₙ)
```

**梯度的性质**：
1. **方向**：指向函数值上升最快的方向
2. **大小**：表示最大变化率
3. **负梯度**：指向函数值下降最快的方向

**代码实现**（与偏导数计算相同，梯度就是所有偏导数组成的向量）：
```python
def compute_gradient(f, x):
    """
    计算梯度向量
    
    参数:
        f: 多元函数
        x: 计算梯度的点
    
    返回:
        梯度向量 ∇f = (∂f/∂x₁, ∂f/∂x₂, ..., ∂f/∂xₙ)
    """
    return numerical_gradient_1d(f, x)  # 梯度就是所有偏导数组成的向量

# 示例：对 f(x,y) = x² + y² 计算梯度
point = np.array([3.0, 4.0])
grad = compute_gradient(function_2, point)
print(f"点 {point} 处的梯度: {grad}")  # 输出: [6. 8.]
print(f"梯度大小: {np.linalg.norm(grad):.2f}")  # 输出: 10.00
```

**几何意义**：
- 在等高线图中，梯度垂直于等高线
- 梯度的模表示函数变化的剧烈程度

---

## 2.3 神经网络的梯度计算

在神经网络的学习中，梯度的计算非常重要。神经网络中的梯度，指的就是损失函数关于权重参数的梯度。

### 2.3.1 权重参数的梯度

我们以一个单层的简单网络为例，形状为 2×3，权重参数为 W，损失函数记为 L。那么它的权重参数和梯度为：

**权重矩阵 W**：
```
W = ┌ w₁₁  w₁₂  w₁₃ ┐
    └ w₂₁  w₂₂  w₂₃ ┘
```

**梯度矩阵 ∂L/∂W**：
```
∂L     ┌ ∂L/∂w₁₁  ∂L/∂w₁₂  ∂L/∂w₁₃ ┐
—— =  └ ∂L/∂w₂₁  ∂L/∂w₂₂  ∂L/∂w₂₃ ┘
∂W
```

**重要说明**：
- 梯度 ∂L/∂W 也是一个 2×3 的矩阵，与权重矩阵形状相同
- 其中各个元素由 L 关于 W 中各元素的偏导数构成
- 例如，∂L/∂w₁₁ 表示当 w₁₁ 稍微变化时，损失函数 L 会发生多大变化

### 2.3.2 梯度计算方法

计算神经网络梯度有两种主要方法：

**1）数值微分法**
- **原理**：使用有限差分近似导数
- **优点**：实现简单，可用于验证
- **缺点**：计算量大，精度有限

**2）解析法（反向传播）**
- **原理**：利用链式法则计算梯度
- **优点**：计算效率高，精度高
- **缺点**：实现较复杂

### 2.3.3 神经网络梯度的数值计算

通过一个简单的神经网络示例，演示梯度计算的完整流程。

**代码实现**（来自 `ch03_train/2_simple_net_grad.py`）：
```python
import numpy as np
from common.functions import softmax, cross_entropy
from common.gradient import numerical_gradient

# SimpleNet: 最简单的神经网络，用于演示梯度计算流程
# 网络结构: 输入层(2个神经元) -> 输出层(3个神经元)
class SimpleNet:
    def __init__(self):
        # 初始化权重矩阵 W，形状为 (2, 3)
        # 2: 输入特征数，3: 输出类别数
        self.W = np.random.randn(2, 3)
    
    def forward(self, x):
        # 前向传播：计算预测概率分布
        a = x @ self.W    # 矩阵乘法：计算加权和
        y = softmax(a)    # 转换为概率分布
        return y
    
    def loss(self, x, t):
        # 计算损失值：预测与真实标签的交叉熵
        y = self.forward(x)
        loss = cross_entropy(y, t)
        return loss

# 主流程：完整的梯度计算示例
if __name__ == '__main__':
    # 第1步：准备数据
    x = np.array([0.6, 0.9])   # 输入数据：2个特征
    t = np.array([0, 0, 1])    # 真实标签：one-hot编码，真实类别为2
    
    # 第2步：创建神经网络
    net = SimpleNet()
    
    # 第3步：计算梯度
    # 将损失函数包装成只关于 W 的函数
    f = lambda w: net.loss(x, t)
    
    # 调用数值梯度计算
    gradw = numerical_gradient(f, net.W)
    print(gradw)
```

**完整计算流程示例**（假设权重为 W = [[0.5,-0.3,0.8],[0.2,0.7,-0.4]]）：

```
【前向传播】
输入: x = [0.6, 0.9]
权重: W = [[ 0.5, -0.3,  0.8],
           [ 0.2,  0.7, -0.4]]

a = x @ W
  = [0.6*0.5 + 0.9*0.2,  0.6*(-0.3) + 0.9*0.7,  0.6*0.8 + 0.9*(-0.4)]
  = [0.48,               0.45,                  0.12]

y = softmax([0.48, 0.45, 0.12])
  = [0.370, 0.359, 0.271]  # 三个类别的预测概率

【计算损失】
真实标签: t = [0, 0, 1] → 真实类别是2
类别2的预测概率: y[2] = 0.271
loss = -log(0.271) = 1.306

【计算梯度】以 W[0,0] 为例：
h = 0.0001

W[0,0] = 0.5 + 0.0001 = 0.5001 → 重新前向传播 → loss1 = 1.3058
W[0,0] = 0.5 - 0.0001 = 0.4999 → 重新前向传播 → loss2 = 1.3062

grad[0,0] = (loss1 - loss2) / (2h) = (1.3058 - 1.3062) / 0.0002 = -0.02

意义：W[0,0]增加时，损失减小，所以梯度为负
梯度下降时：W[0,0] = W[0,0] - lr * grad[0,0]
由于 grad 为负，所以 W[0,0] 会增大，损失继续减小
```

**代码说明**：
- SimpleNet 是最简单的神经网络，只有一层权重
- `forward` 方法执行前向传播，计算预测概率
- `loss` 方法计算交叉熵损失
- `numerical_gradient` 计算损失函数对权重的梯度
- 梯度矩阵与权重矩阵形状相同

### 2.3.4 梯度检验

用数值梯度验证解析梯度的正确性：

```
相对误差 = |数值梯度 - 解析梯度| / max(|数值梯度|, |解析梯度|)
```

**判断标准**：
- 相对误差 < 1e-7：梯度计算正确
- 相对误差 > 1e-5：可能存在问题

---

## 2.4 随机梯度下降法（SGD）

### 2.4.1 梯度下降法

梯度下降法是最基本的优化算法，通过沿负梯度方向迭代更新参数来最小化损失函数。

**更新公式**：
```
θ = θ - η·∇L(θ)
```

其中：
- θ：模型参数
- η：学习率（learning rate）
- ∇L(θ)：损失函数关于参数的梯度

**梯度下降的变体**：

| 方法 | 描述 | 特点 |
|-----|------|------|
| 批量梯度下降（BGD） | 使用全部数据计算梯度 | 稳定但慢 |
| 随机梯度下降（SGD） | 使用单个样本计算梯度 | 快但不稳定 |
| 小批量梯度下降（Mini-batch） | 使用一小批数据 | 平衡稳定性和速度 |

**代码实现**：
```python
def gradient_descent(f, init_x, lr=0.01, step_num=100):
    """
    梯度下降法求函数最小值
    
    参数:
        f: 目标函数（要最小化的函数）
        init_x: 初始参数值
        lr: 学习率（learning rate）
        step_num: 迭代次数
    
    返回:
        x: 优化后的参数值
    """
    x = init_x.copy()  # 复制初始值，避免修改原数组
    
    for i in range(step_num):
        # 计算当前点的梯度
        grad = numerical_gradient_1d(f, x)
        # 沿负梯度方向更新参数
        x = x - lr * grad
    
    return x

# 示例：求 f(x₀, x₁) = x₀² + x₁² 的最小值点
init_x = np.array([-3.0, 4.0])
result = gradient_descent(function_2, init_x, lr=0.1, step_num=100)
print(result)  # 输出接近 [0, 0]
```

**代码说明**：
- 每次迭代计算梯度，然后沿负梯度方向更新参数
- 学习率 lr 控制每步移动的大小
- 复制初始值是为了不修改传入的原始数组

### 2.4.2 模型训练相关概念

#### Epoch（轮次）

一个 epoch 表示所有训练数据被完整使用一次。

```
训练过程：Epoch 1 → Epoch 2 → ... → Epoch N
```

#### Batch Size（批量大小）

每次更新参数时使用的样本数量。

**选择建议**：
- 常用值：32, 64, 128, 256
- 内存限制：根据GPU显存调整
- 收敛性：较大的batch更稳定，较小的batch噪声更大但可能找到更好的解

#### Iteration（迭代次数）

```
迭代次数 = 训练样本数 / Batch Size
```

**示例**：
- 训练集：10000个样本
- Batch Size：100
- 每个Epoch的迭代次数：10000 / 100 = 100次

#### 学习率（Learning Rate）

学习率决定了参数更新的步长。

**学习率的影响**：
- 太大：可能跳过最优解，导致震荡或发散
- 太小：收敛速度慢
- 合适：稳定收敛到最优解

**学习率调整策略**：
1. 固定学习率
2. 学习率衰减（Step Decay, Exponential Decay）
3. 自适应学习率（Adam, RMSprop）

### 2.4.3 SGD

随机梯度下降（Stochastic Gradient Descent）是最基础的优化算法。

**算法流程**：
```
1. 初始化参数 θ
2. 重复以下步骤直到收敛：
   a. 随机选择一个（或一批）样本
   b. 计算损失函数关于参数的梯度
   c. 更新参数：θ = θ - η·∇L(θ)
```

**代码实现**：
```python
class SGD:
    """
    随机梯度下降优化器
    
    参数:
        lr: 学习率 (learning rate)
    """
    def __init__(self, lr=0.01):
        self.lr = lr
    
    def update(self, params, grads):
        """
        更新参数
        
        参数:
            params: 参数字典，如 {'W1': ..., 'b1': ..., 'W2': ..., 'b2': ...}
            grads: 梯度字典，与 params 结构相同
        """
        for key in params.keys():
            # 更新公式：θ = θ - η·∇L(θ)
            params[key] -= self.lr * grads[key]

# 使用示例
optimizer = SGD(lr=0.01)
optimizer.update(network.params, grads)  # 一次参数更新
```

**代码说明**：
- 将优化器封装为类，便于管理和替换
- `update` 方法直接修改传入的 params 字典
- 简单易懂，但可以扩展为 Momentum、Adam 等更复杂的优化器

**SGD的优缺点**：

| 优点 | 缺点 |
|-----|------|
| 实现简单 | 学习率难以选择 |
| 计算效率高 | 容易陷入局部最优 |
| 在线学习 | 在鞍点处收敛慢 |
| 有助于跳出局部最优 | 震荡现象 |

**SGD的改进版本**：
1. **动量（Momentum）**：引入历史梯度信息
2. **Nesterov动量**：预测下一步位置后再计算梯度
3. **AdaGrad**：自适应调整每个参数的学习率
4. **RMSprop**：解决AdaGrad学习率衰减过快问题
5. **Adam**：结合动量和自适应学习率

---

## 2.5 综合代码实现

本节将整合以上所有概念，实现一个完整的神经网络训练流程。

### 训练流程概览

```
1. 数据准备
   ↓
2. 网络初始化
   ↓
3. 前向传播（计算预测值）
   ↓
4. 计算损失（损失函数）
   ↓
5. 反向传播（计算梯度）
   ↓
6. 参数更新（SGD）
   ↓
7. 重复步骤3-6直到收敛
```

### 完整实现

```python
import numpy as np
from common.functions import sigmoid, softmax, cross_entropy

class TwoLayerNet:
    """
    两层神经网络类
    
    网络结构:
        输入层 (input_size) → 隐藏层 (hidden_size) → 输出层 (output_size)
    """
    
    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):
        """
        初始化网络参数
        
        参数:
            input_size: 输入层大小（特征数）
            hidden_size: 隐藏层神经元数
            output_size: 输出层大小（类别数）
            weight_init_std: 权重初始化标准差
        """
        # 参数字典：存储网络所有可训练参数
        self.params = {}
        
        # 输入层 → 隐藏层
        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)
        self.params['b1'] = np.zeros(hidden_size)
        
        # 隐藏层 → 输出层
        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b2'] = np.zeros(output_size)
    
    def predict(self, x):
        """
        前向传播：根据输入计算预测输出
        
        参数:
            x: 输入数据，形状 (batch_size, input_size)
        
        返回:
            y: 预测概率分布，形状 (batch_size, output_size)
        """
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']
        
        # 第一层：输入层 → 隐藏层
        a1 = np.dot(x, W1) + b1  # 加权和
        z1 = sigmoid(a1)         # 激活
        
        # 第二层：隐藏层 → 输出层
        a2 = np.dot(z1, W2) + b2  # 加权和
        y = softmax(a2)           # Softmax激活，输出概率
        
        return y
    
    def loss(self, x, t):
        """
        计算损失函数值
        
        参数:
            x: 输入数据
            t: 真实标签（one-hot 或类别索引）
        
        返回:
            交叉熵损失值
        """
        y = self.predict(x)
        return cross_entropy(y, t)
    
    def accuracy(self, x, t):
        """
        计算分类准确率
        
        参数:
            x: 输入数据
            t: 真实标签
        
        返回:
            准确率 (正确数 / 总数)
        """
        y = self.predict(x)
        y = np.argmax(y, axis=1)  # 预测类别
        if t.ndim != 1:
            t = np.argmax(t, axis=1)  # 将 one-hot 转为类别索引
        
        return np.sum(y == t) / float(x.shape[0])
    
    def numerical_gradient(self, x, t):
        """
        计算所有参数的梯度（数值微分法）
        
        参数:
            x: 输入数据
            t: 真实标签
        
        返回:
            梯度字典，与 params 结构相同
        """
        loss_W = lambda W: self.loss(x, t)  # 损失函数
        
        grads = {}
        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])
        
        return grads

# ==================== 训练主流程 ====================
if __name__ == "__main__":
    # 1. 准备数据（示例：简化的手写数字数据）
    from sklearn.datasets import load_digits
    from sklearn.model_selection import train_test_split
    
    digits = load_digits()
    X = digits.data / 16.0  # 归一化到 [0, 1]
    y = digits.target
    
    # 划分训练集和测试集
    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    
    # 2. 初始化网络
    network = TwoLayerNet(input_size=64, hidden_size=50, output_size=10)
    
    # 3. 设置超参数
    iters_num = 1000     # 迭代次数
    batch_size = 100      # 批次大小
    learning_rate = 0.1   # 学习率
    
    train_size = x_train.shape[0]
    train_loss_list = []   # 记录损失变化
    train_acc_list = []    # 记录训练准确率
    test_acc_list = []     # 记录测试准确率
    
    # 4. 训练循环
    for i in range(iters_num):
        # (a) 随机抽取 mini-batch
        batch_mask = np.random.choice(train_size, batch_size)
        x_batch = x_train[batch_mask]
        t_batch = y_train[batch_mask]
        
        # (b) 计算梯度
        grad = network.numerical_gradient(x_batch, t_batch)
        
        # (c) 更新参数 (SGD)
        for key in ('W1', 'b1', 'W2', 'b2'):
            network.params[key] -= learning_rate * grad[key]
        
        # (d) 记录损失
        loss = network.loss(x_batch, t_batch)
        train_loss_list.append(loss)
        
        # 每 100 次迭代打印一次进度
        if i % 100 == 0:
            train_acc = network.accuracy(x_train, y_train)
            test_acc = network.accuracy(x_test, y_test)
            train_acc_list.append(train_acc)
            test_acc_list.append(test_acc)
            print(f"iter {i:4d} | loss: {loss:.4f} | train_acc: {train_acc:.4f} | test_acc: {test_acc:.4f}")
    
    print(f"\n训练完成！最终测试准确率: {network.accuracy(x_test, y_test):.4f}")
```

**代码说明**：

1. **网络类结构**：
   - `__init__`: 初始化权重和偏置，使用正态分布随机初始化
   - `predict`: 前向传播，计算预测结果
   - `loss`: 计算交叉熵损失
   - `accuracy`: 计算分类准确率
   - `numerical_gradient`: 计算所有参数的梯度

2. **训练流程**：
   - 随机抽取 mini-batch
   - 计算梯度
   - SGD 更新参数
   - 记录损失和准确率

3. **关键设计**：
   - 使用字典存储参数，便于统一管理
   - 数值梯度用于教学演示，实际应用中使用反向传播更高效

### 训练技巧总结

1. **数据预处理**：
   - 特征归一化/标准化
   - 数据增强
   - 打乱训练数据顺序

2. **参数初始化**：
   - Xavier初始化
   - He初始化
   - 避免全零初始化

3. **学习率设置**：
   - 从较大值开始尝试
   - 观察损失曲线调整
   - 使用学习率调度器

4. **防止过拟合**：
   - Dropout
   - L2正则化
   - Early Stopping
   - 数据增强

5. **监控训练过程**：
   - 记录训练/验证损失
   - 可视化学习曲线
   - 定期保存模型检查点

---

## 总结

本章介绍了神经网络学习的核心概念：

### 理论基础

1. **损失函数**：
   - 分类任务：交叉熵损失
   - 回归任务：MSE、MAE
   - 损失函数的选择影响训练效果

2. **数值微分**：
   - 导数和偏导数的数值计算
   - 梯度的概念和几何意义
   - 中心差分法提高精度

3. **梯度计算**：
   - 神经网络梯度的数值计算方法
   - 梯度检验确保实现正确性

4. **优化算法**：
   - 梯度下降法的原理
   - Epoch、Batch Size、Iteration的概念
   - SGD及其改进版本

### 关键收获

✅ 理解损失函数的作用和选择原则  
✅ 掌握数值微分和梯度计算方法  
✅ 理解梯度下降法的工作原理  
✅ 掌握训练相关的核心概念（Epoch、Batch、学习率）  
✅ 了解SGD优化器及其改进版本  

### 后续学习方向

1. **反向传播算法**：利用链式法则高效计算梯度
2. **高级优化器**：Adam、RMSprop等自适应优化器
3. **正则化技术**：防止过拟合的各种方法
4. **学习率调度**：动态调整学习率的策略
5. **分布式训练**：大规模数据的并行训练

# 第7章 卷积神经网络

## 本章导读

卷积神经网络（Convolutional Neural Network，CNN）是深度学习中最重要、应用最广泛的网络结构之一。它在计算机视觉领域取得了革命性的突破，广泛应用于图像分类、目标检测、图像分割等任务。

**学习目标**：
- 理解卷积神经网络的基本原理和核心思想
- 掌握卷积运算、填充、步幅等关键技术
- 理解池化层的作用和实现方式
- 熟悉经典CNN网络结构（LeNet、AlexNet、VGG、ResNet等）
- 能够使用PyTorch构建和训练CNN模型

**学习路线**：
```
CNN概述 → 卷积层 → 池化层 → 深度CNN → 实战应用
(核心思想) (特征提取) (降维采样) (经典网络) (服装分类)
```

**核心概念**：
- 局部感受野：卷积核只关注局部区域
- 权重共享：同一卷积核在整个输入上共享参数
- 特征图：卷积运算后得到的输出
- 通道：数据的深度维度，表示不同特征

---

## 7.1 CNN概述

### 7.1.1 为什么需要CNN

传统的全连接神经网络在处理图像时面临以下问题：

1. **参数数量爆炸**：对于1000×1000像素的彩色图像，输入层有3,000,000个神经元。如果第一层有1000个神经元，则需要30亿个参数。

2. **忽略空间结构**：全连接层将图像展平为一维向量，丢失了像素之间的空间关系。

3. **缺乏平移不变性**：全连接网络无法识别图像中平移后的相同模式。

### 7.1.2 CNN的核心思想

卷积神经网络通过以下三个关键特性解决上述问题：

#### 1. 局部连接（Sparse Connectivity）

每个神经元只与输入数据的局部区域连接，而不是与所有输入连接。

**优势**：
- 大幅减少参数数量
- 每个神经元专注于提取局部特征（如边缘、纹理）
- 符合图像的局部相关性特点

#### 2. 权重共享（Shared Weights）

同一个卷积核（滤波器）在整个输入图像上滑动，使用相同的权重参数。

**优势**：
- 进一步减少参数数量
- 使网络具有平移不变性
- 能够检测图像中任意位置的特征

#### 3. 层次化特征学习

CNN通过多层结构逐层提取特征：

| 层次 | 提取特征 | 特点 |
|------|---------|------|
| 浅层 | 边缘、颜色、纹理 | 低级、通用特征 |
| 中层 | 形状、轮廓、部件 | 中级、组合特征 |
| 深层 | 物体、场景、语义 | 高级、抽象特征 |

### 7.1.3 CNN的基本结构

一个典型的CNN包含以下组件：

```
输入图像 → [卷积层 + 激活函数] → [池化层] → [卷积层 + 激活函数] → [池化层] → 全连接层 → 输出
```

**各层作用**：
- **卷积层**：提取局部特征
- **激活层**：引入非线性
- **池化层**：降维、减少计算量
- **全连接层**：分类或回归

### 7.1.4 CNN的应用领域

卷积神经网络在多个领域取得了显著成果：

1. **计算机视觉**
   - 图像分类（ImageNet竞赛）
   - 目标检测（YOLO、Faster R-CNN）
   - 图像分割（语义分割、实例分割）
   - 人脸识别

2. **自然语言处理**
   - 文本分类
   - 情感分析
   - 机器翻译

3. **其他领域**
   - 医学影像分析
   - 自动驾驶
   - 语音识别
   - 推荐系统

---

## 7.2 卷积层

卷积层是CNN的核心组件，负责从输入数据中提取特征。

### 7.2.1 卷积运算

#### 数学定义

卷积运算通过卷积核（滤波器）在输入数据上滑动，计算局部区域的点积。

对于二维输入$X$和卷积核$K$，卷积运算定义为：

$$
Y[i,j] = \sum_{m=0}^{k_h-1} \sum_{n=0}^{k_w-1} X[i+m, j+n] \cdot K[m, n] + b
$$

其中：
- $X$：输入特征图
- $K$：卷积核（大小为$k_h \times k_w$）
- $b$：偏置项
- $Y$：输出特征图

#### 卷积运算示例

考虑一个简单的3×3卷积核：

```
卷积核 K = [[1, 0, -1],
            [1, 0, -1],
            [1, 0, -1]]
```

这是一个垂直边缘检测器，能够检测图像中的垂直边缘。

**运算过程**：
1. 将卷积核放置在输入图像的左上角
2. 计算卷积核与对应区域的逐元素乘积之和
3. 将结果存入输出特征图的对应位置
4. 滑动卷积核，重复上述过程

#### 卷积核的类型

| 卷积核类型 | 作用 | 示例 |
|-----------|------|------|
| 边缘检测 | 检测图像边缘 | [[-1,-1,-1], [-1,8,-1], [-1,-1,-1]] |
| 锐化 | 增强图像细节 | [[0,-1,0], [-1,5,-1], [0,-1,0]] |
| 模糊 | 平滑图像 | [[1/9,1/9,1/9], [1/9,1/9,1/9], [1/9,1/9,1/9]] |
| 高斯模糊 | 加权平滑 | 高斯分布权重 |

#### 输出尺寸计算

输出特征图的尺寸由以下公式计算：

$$
H_{out} = \frac{H_{in} - k_h + 2p}{s} + 1
$$

$$
W_{out} = \frac{W_{in} - k_w + 2p}{s} + 1
$$

其中：
- $H_{in}, W_{in}$：输入高度和宽度
- $k_h, k_w$：卷积核高度和宽度
- $p$：填充大小
- $s$：步幅

### 7.2.2 填充（Padding）

#### 为什么需要填充

1. **保持空间尺寸**：避免卷积后特征图尺寸过快减小
2. **保留边缘信息**：使边缘像素参与更多卷积运算
3. **控制输出尺寸**：灵活调整输出特征图的大小

#### 填充类型

**1. Valid填充（无填充）**
- 不进行任何填充
- 输出尺寸：$(H - k + 1) \times (W - k + 1)$
- 缺点：边缘信息丢失，特征图尺寸快速减小

**2. Same填充**
- 填充使得输出尺寸与输入尺寸相同
- 填充大小：$p = \frac{k-1}{2}$（假设步幅为1）
- 优点：保持空间分辨率

**3. Full填充**
- 充分填充使得每个输入像素都参与相同次数的卷积
- 填充大小：$p = k - 1$
- 输出尺寸大于输入尺寸

#### 填充的数学表达

对于大小为$k$的卷积核，Same填充需要在输入的四周各填充$p = \lfloor k/2 \rfloor$个像素。

**示例**：
- 3×3卷积核：填充1个像素
- 5×5卷积核：填充2个像素
- 7×7卷积核：填充3个像素

### 7.2.3 步幅（Stride）

步幅定义了卷积核每次滑动的距离。

#### 步幅的作用

1. **降维**：大步幅可以快速减小特征图尺寸
2. **减少计算量**：减少卷积运算次数
3. **增大感受野**：间接增大后续层的感受野

#### 步幅与输出尺寸

步幅为$s$时，输出尺寸为：

$$
H_{out} = \lfloor \frac{H_{in} - k + 2p}{s} \rfloor + 1
$$

**常见配置**：
- 步幅1：精细特征提取，保持空间分辨率
- 步幅2：快速降维，常用于下采样

### 7.2.4 3维数据的卷积运算

实际应用中，输入数据通常是3维的：高度×宽度×通道数（H×W×C）。

#### 多通道卷积

对于多通道输入，卷积核也有相同的通道数，每个通道独立进行卷积，然后将结果相加。

**运算过程**：
1. 输入：$H \times W \times C_{in}$
2. 卷积核：$k \times k \times C_{in}$
3. 输出：$H_{out} \times W_{out} \times 1$

#### 多输出通道

为了提取多种特征，通常使用多个卷积核，每个卷积核产生一个输出通道。

**运算过程**：
1. 输入：$H \times W \times C_{in}$
2. 卷积核组：$C_{out}$个卷积核，每个大小为$k \times k \times C_{in}$
3. 输出：$H_{out} \times W_{out} \times C_{out}$

**参数数量**：$C_{out} \times (k \times k \times C_{in} + 1)$（包含偏置）

### 7.2.5 API使用

PyTorch提供了`nn.Conv2d`类来实现二维卷积层。

**主要参数**：

| 参数 | 说明 | 默认值 |
|------|------|--------|
| in_channels | 输入通道数 | 必需 |
| out_channels | 输出通道数 | 必需 |
| kernel_size | 卷积核大小 | 必需 |
| stride | 步幅 | 1 |
| padding | 填充大小 | 0 |
| dilation | 空洞卷积率 | 1 |
| groups | 分组卷积组数 | 1 |
| bias | 是否使用偏置 | True |

**基础代码示例**：

```python
import torch
import torch.nn as nn

# 定义卷积层
conv = nn.Conv2d(
    in_channels=3,      # 输入通道数（RGB图像）
    out_channels=16,    # 输出通道数（16个特征图）
    kernel_size=3,      # 3×3卷积核
    stride=1,           # 步幅为1
    padding=1           # 填充1个像素（Same填充）
)

# 输入数据：batch_size=4, channels=3, height=32, width=32
input = torch.randn(4, 3, 32, 32)

# 前向传播
output = conv(input)

print(f"输入形状: {input.shape}")
print(f"输出形状: {output.shape}")
print(f"卷积核形状: {conv.weight.shape}")
print(f"偏置形状: {conv.bias.shape}")
```

**输出**：
```
输入形状: torch.Size([4, 3, 32, 32])
输出形状: torch.Size([4, 16, 32, 32])
卷积核形状: torch.Size([16, 3, 3, 3])
偏置形状: torch.Size([16])
```

**完整示例：离散序列卷积与图像卷积**（来自 `ch08_cnn/1_conv_test.ipynb`）：

```python
import numpy as np
import torch
import matplotlib.pyplot as plt

# 离散序列的卷积运算示例
f = [2, 3, 5, 1, 4, 6, 3, 2, 5]
g = [1/3, 1/3, 1/3]

# 使用numpy进行一维卷积
print("序列f:", f)
print("卷积核g:", g)
print("卷积结果:", np.convolve(f, g, mode='valid'))

# 图像卷积处理示例
# 1. 读取图片
img = plt.imread("../data/duck.jpg")

# 2. 将图片数据调整为卷积层输入特征图对应的形状
# 从[H, W, C]转换为[C, H, W]
input_tensor = torch.tensor(img).permute(2, 0, 1).float()
print(f"输入图片形状: {input_tensor.shape}")  # torch.Size([3, 1080, 1080])

# 3. 定义卷积层
conv = torch.nn.Conv2d(
    in_channels=3,
    out_channels=3,
    kernel_size=9,
    stride=3,
    padding=0
)

# 4. 前向传播，将卷积层应用到输入特征图上
output = conv(input_tensor)
print(f"卷积后输出形状: {output.shape}")  # torch.Size([3, 358, 358])

# 5. 将输出特征图转换为图片数据用于显示
output_img = torch.clamp(output.int(), min=0, max=255)
output_img = output_img.permute(1, 2, 0).detach().numpy()

# 显示图片，进行对比
fig, ax = plt.subplots(1, 2, figsize=(10, 5))
ax[0].imshow(img)
ax[0].set_title("原始图片")
ax[1].imshow(output_img)
ax[1].set_title("卷积处理后")
plt.show()
```

---

## 7.3 池化层

池化层（Pooling Layer）用于降低特征图的空间尺寸，减少计算量，同时增强特征的鲁棒性。

### 7.3.1 池化层的作用

1. **降维**：减少特征图的高度和宽度
2. **减少参数量**：降低后续层的计算负担
3. **增强平移不变性**：使网络对小的位置变化更鲁棒
4. **防止过拟合**：减少模型复杂度

### 7.3.2 最大池化（Max Pooling）

最大池化在池化窗口内选择最大值作为输出。

**运算过程**：
```
输入区域：[[1, 3],
          [2, 4]]
          
最大池化输出：4
```

**特点**：
- 保留最强激活值
- 对边缘和纹理特征敏感
- 最常用，效果通常最好

### 7.3.3 平均池化（Average Pooling）

平均池化计算池化窗口内所有值的平均值。

**运算过程**：
```
输入区域：[[1, 3],
          [2, 4]]
          
平均池化输出：(1+3+2+4)/4 = 2.5
```

**特点**：
- 保留背景信息
- 对位置信息不敏感
- 常用于网络最后一层

### 7.3.4 全局池化

全局池化将整个特征图池化为一个值。

**类型**：
- **全局最大池化（GMP）**：取整个特征图的最大值
- **全局平均池化（GAP）**：取整个特征图的平均值

**优势**：
- 将任意尺寸的特征图转换为固定长度向量
- 大幅减少参数量
- 替代全连接层，减少过拟合

### 7.3.5 池化层API

PyTorch提供了多种池化层实现。

**基础代码示例**：

```python
import torch
import torch.nn as nn

# 最大池化
max_pool = nn.MaxPool2d(
    kernel_size=2,    # 2×2池化窗口
    stride=2          # 步幅为2
)

# 平均池化
avg_pool = nn.AvgPool2d(
    kernel_size=2,
    stride=2
)

# 全局平均池化
gap = nn.AdaptiveAvgPool2d((1, 1))

# 输入数据
input = torch.randn(4, 16, 32, 32)

# 前向传播
output_max = max_pool(input)
output_avg = avg_pool(input)
output_gap = gap(input)

print(f"输入形状: {input.shape}")
print(f"最大池化输出: {output_max.shape}")
print(f"平均池化输出: {output_avg.shape}")
print(f"全局平均池化输出: {output_gap.shape}")
```

**输出**：
```
输入形状: torch.Size([4, 16, 32, 32])
最大池化输出: torch.Size([4, 16, 16, 16])
平均池化输出: torch.Size([4, 16, 16, 16])
全局平均池化输出: torch.Size([4, 16, 1, 1])
```

**完整示例：卷积与池化的组合应用**（来自 `ch08_cnn/2_pooling_test.ipynb`）：

```python
import torch
import matplotlib.pyplot as plt

# 1. 读取图片
img = plt.imread("../data/duck.jpg")

# 2. 将图片数据调整为卷积层输入特征图对应的形状
# 从[H, W, C]转换为[C, H, W]
input_tensor = torch.tensor(img).permute(2, 0, 1).float()
print(f"输入图片形状: {input_tensor.shape}")  # torch.Size([3, 1080, 1080])

# 3. 定义卷积层
conv = torch.nn.Conv2d(
    in_channels=3,
    out_channels=3,
    kernel_size=9,
    stride=3,
    padding=0
)

# 4. 前向传播，将卷积层应用到输入特征图上
output = conv(input_tensor)
print(f"卷积后输出形状: {output.shape}")  # torch.Size([3, 358, 358])

# 5. 定义池化层
pool = torch.nn.MaxPool2d(
    kernel_size=6,
    stride=6,
    padding=1
)

# 6. 前向传播，池化操作
output2 = pool(output)
print(f"池化后输出形状: {output2.shape}")  # torch.Size([3, 60, 60])

# 7. 将输出特征图转换为图片数据用于显示
output_img = torch.clamp(output.int(), min=0, max=255)
output_img = output_img.permute(1, 2, 0).detach().numpy()

output2_img = torch.clamp(output2.int(), min=0, max=255)
output2_img = output2_img.permute(1, 2, 0).detach().numpy()

# 显示图片，进行对比
fig, ax = plt.subplots(1, 3, figsize=(10, 5))
ax[0].imshow(img)
ax[0].set_title("原始图片")
ax[1].imshow(output_img)
ax[1].set_title("卷积处理后")
ax[2].imshow(output2_img)
ax[2].set_title("卷积+池化处理后")
plt.show()
```

### 7.3.6 池化 vs 卷积（步幅>1）

两者都可以降维，但有区别：

| 特性 | 池化 | 步幅卷积 |
|------|------|---------|
| 运算 | 取最大/平均 | 卷积运算 |
| 参数量 | 无 | 有 |
| 特征保留 | 保留显著特征 | 学习降维方式 |
| 计算量 | 小 | 大 |
| 趋势 | 现代网络倾向使用 | ResNet等使用 |

---

## 7.4 深度卷积神经网络

### 7.4.1 经典CNN架构演进

#### LeNet（1998）

LeNet是最早的卷积神经网络之一，由Yann LeCun提出，用于手写数字识别。

**结构**：
```
输入(32×32) → Conv(6@5×5) → MaxPool(2×2) → Conv(16@5×5) → MaxPool(2×2) 
→ FC(120) → FC(84) → 输出(10)
```

**特点**：
- 5层网络（2卷积+3全连接）
- 使用Sigmoid/Tanh激活函数
- 参数约6万

#### AlexNet（2012）

AlexNet在ImageNet竞赛中以巨大优势获胜，开启了深度学习时代。

**结构特点**：
- 8层网络（5卷积+3全连接）
- 使用ReLU激活函数
- 使用Dropout正则化
- 使用GPU并行训练
- 参数约6000万

**创新点**：
1. ReLU激活：加速收敛，缓解梯度消失
2. GPU并行：使用两块GPU训练
3. 局部响应归一化（LRN）：增强泛化能力
4. Dropout：防止过拟合
5. 数据增强：扩大训练集

#### VGGNet（2014）

VGGNet由牛津大学Visual Geometry Group提出，以简洁和深度著称。

**核心思想**：
- 使用小卷积核（3×3）替代大卷积核
- 通过堆叠增加网络深度
- 结构规整，易于理解和实现

**VGG-16结构**：
```
输入(224×224×3)
→ Conv64×2 → MaxPool
→ Conv128×2 → MaxPool
→ Conv256×3 → MaxPool
→ Conv512×3 → MaxPool
→ Conv512×3 → MaxPool
→ FC4096 → FC4096 → FC1000
```

**3×3卷积核的优势**：
- 两个3×3卷积核的感受野等于一个5×5卷积核
- 参数更少：$2 \times 3^2 = 18 < 25 = 5^2$
- 更多非线性：两次ReLU vs 一次ReLU

#### ResNet（2015）

ResNet（残差网络）通过引入残差连接解决了深层网络的梯度消失问题，可以训练非常深的网络（152+层）。

**核心思想：残差学习**

传统网络学习：$H(x)$
残差网络学习：$F(x) = H(x) - x$，即残差

**残差块结构**：
```
输入 x ──→ [Conv → BN → ReLU → Conv → BN] ──→ ⊕ ──→ ReLU ──→ 输出
      └──────────────────────────────────────────┘
                        +
                      恒等映射
```

**优势**：
1. 解决梯度消失：恒等映射提供梯度捷径
2. 易于优化：残差比原始映射更容易学习
3. 网络可以很深：ResNet-152、ResNet-1000+

**ResNet的变体**：
- ResNet-18/34：基础残差块
- ResNet-50/101/152：使用瓶颈结构（1×1→3×3→1×1）

**使用torchvision加载预训练模型**（来自 `ch08_cnn/3_deep_cnn.ipynb`）：

```python
import torchvision.models as models

# 1. 加载AlexNet
alexnet = models.alexnet(pretrained=True)
print(alexnet)

# 2. 加载VGG-16
vgg16 = models.vgg16(pretrained=True)
print(vgg16)

# 3. 加载GoogLeNet
googlenet = models.googlenet()
print(googlenet)

# 4. 加载ResNet-50
resnet50 = models.resnet50()
print(resnet50)
```

**说明**：
- `pretrained=True`：加载在ImageNet上预训练的权重
- 这些模型可以直接用于特征提取或迁移学习
- 根据任务需求，可以修改最后的全连接层进行微调

### 7.4.2 现代CNN设计趋势

#### 1. 更深的网络

- ResNet：152+层
- DenseNet：密集连接
- EfficientNet：复合缩放

#### 2. 更轻量的网络

- MobileNet：深度可分离卷积
- ShuffleNet：通道混洗
- SqueezeNet：压缩网络

#### 3. 注意力机制

- SE-Net：通道注意力
- CBAM：通道+空间注意力
- Non-local：全局注意力

#### 4. 神经网络架构搜索（NAS）

- AutoML：自动搜索最优架构
- EfficientNet：通过NAS发现

### 7.4.3 CNN设计原则

1. **从浅到深**：逐步提取高级特征
2. **空间降维**：通过池化或步幅卷积减少空间尺寸
3. **通道增加**：深层网络通常有更多通道
4. **残差连接**：深层网络使用残差连接
5. **批归一化**：稳定训练，加速收敛

---

## 7.5 案例：服装分类

本节将使用CNN实现Fashion-MNIST服装分类任务。

### 7.5.1 加载数据

Fashion-MNIST数据集包含10个类别的服装图像，每个图像是28×28的灰度图。

**类别**：
0. T-shirt/top（T恤）
1. Trouser（裤子）
2. Pullover（套衫）
3. Dress（连衣裙）
4. Coat（外套）
5. Sandal（凉鞋）
6. Shirt（衬衫）
7. Sneaker（运动鞋）
8. Bag（包）
9. Ankle boot（短靴）

**完整代码实现**（来自 `ch08_cnn/4.fashion_category.py`）：

```python
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import TensorDataset, DataLoader

# 1. 加载数据
fashion_data = pd.read_csv('../data/fashion-mnist_train.csv').fillna(0)  # 填充NaN为0
fashion_test = pd.read_csv('../data/fashion-mnist_test.csv').fillna(0)  # 填充NaN为0

# 提取X和y，转换为张量
x_train = fashion_data.iloc[:, 1:].values
x_train = torch.tensor(x_train, dtype=torch.float).reshape(-1, 1, 28, 28)
y_train = fashion_data.iloc[:, 0].values
y_train = torch.tensor(y_train, dtype=torch.int64)

x_test = fashion_test.iloc[:, 1:].values
x_test = torch.tensor(x_test, dtype=torch.float).reshape(-1, 1, 28, 28)
y_test = fashion_test.iloc[:, 0].values
y_test = torch.tensor(y_test, dtype=torch.int64)

# 构建数据集
train_dataset = TensorDataset(x_train, y_train)
test_dataset = TensorDataset(x_test, y_test)
```

### 7.5.2 搭建模型

构建一个LeNet风格的CNN模型用于服装分类。

**模型结构**：
```
输入(1×28×28)
→ Conv(6@5×5) → Sigmoid → AvgPool(2×2)
→ Conv(16@5×5) → Sigmoid → AvgPool(2×2)
→ Flatten
→ FC(120) → Sigmoid
→ FC(84) → Sigmoid
→ FC(10)
```

**代码实现**：

```python
# 2. 创建模型
model = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),
    nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),
    nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Flatten(),
    nn.Linear(in_features=400, out_features=120),
    nn.Sigmoid(),
    nn.Linear(in_features=120, out_features=84),
    nn.Sigmoid(),
    nn.Linear(in_features=84, out_features=10)
)

# 查看每层的输出形状
x = torch.rand(size=(1, 1, 28, 28), dtype=torch.float)
for layer in model:
    x = layer(x)
    print(f"{layer.__class__.__name__}: {x.shape}")
```

### 7.5.3 模型训练

实现完整的训练流程，包括训练循环和测试评估。

**代码实现**：

```python
# 3. 训练模型
def train_test(model, train_dataset, test_dataset, lr, epoch_num, batch_size, device):
    # 参数初始化函数
    def init_params(layer):
        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):
            nn.init.xavier_uniform_(layer.weight)
    
    # 3.1 初始化相关操作
    model.apply(init_params)
    model.to(device)
    loss = nn.CrossEntropyLoss()
    # 定义优化器
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    # 3.2 训练过程
    for epoch in range(epoch_num):
        model.train()
        # 定义DataLoader
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        train_loss = 0
        train_correct_num = 0
        
        # 循环迭代
        for batch_idx, (X, y) in enumerate(train_loader):
            X, y = X.to(device), y.to(device)
            
            # 3.2.1 前向传播
            output = model(X)
            # 3.2.2 计算损失
            loss_value = loss(output, y)
            # 3.2.3 反向传播
            loss_value.backward()
            # 3.2.4 更新参数
            optimizer.step()
            # 3.2.5 梯度清零
            optimizer.zero_grad()
            
            # 累计损失
            train_loss += loss_value.item() * X.shape[0]
            # 累加预测正确的数量
            pred = output.argmax(dim=1)
            train_correct_num += (pred == y).sum()

            # 打印进度条
            print(f"\rEpoch:{epoch+1:0>2}[{'='* int((batch_idx+1)/len(train_loader)*50)}]", end="")
        
        # 一轮结束，计算平均误差和准确率
        this_loss = train_loss / len(train_dataset)
        accuracy = train_correct_num / len(train_dataset)

        # 3.3 测试验证
        model.eval()
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)
        test_correct_num = 0
        
        # 迭代预测，进行准确数量的累加
        with torch.no_grad():
            for X, y in test_loader:
                X, y = X.to(device), y.to(device)
                output = model(X)
                pred = output.argmax(dim=1)
                test_correct_num += (pred == y).sum()
        
        # 计算准确率
        this_test_accuracy = test_correct_num / len(test_dataset)

        print(f"train_loss: {this_loss:.4f}, train_acc: {accuracy:.4f}, test_acc: {this_test_accuracy:.4f}")

# 设置设备
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# 超参数
lr = 0.01
epoch_num = 20
batch_size = 256

# 开始训练
train_test(model, train_dataset, test_dataset, lr, epoch_num, batch_size, device)

# 选取一个数据，进行测试对比
plt.imshow(x_test[666, 0, :, :], cmap='gray')
plt.show()
print(f"真实标签: {y_test[666]}")

# 传入模型，前向传播，进行预测
output = model(x_test[666].unsqueeze(0).to(device))
y_pred = output.argmax(dim=1)
print(f"预测标签: {y_pred}")
```

---

## 本章小结

### 核心概念回顾

1. **卷积神经网络的核心思想**：
   - 局部连接：减少参数，提取局部特征
   - 权重共享：平移不变性，进一步减少参数
   - 层次化特征：从低级到高级特征逐层提取

2. **卷积层关键技术**：
   - 卷积运算：提取局部特征
   - 填充：保持空间尺寸，保留边缘信息
   - 步幅：控制降维速度
   - 多通道：提取多种特征

3. **池化层作用**：
   - 降维：减少计算量
   - 平移不变性：增强鲁棒性
   - 防止过拟合：减少参数

4. **经典CNN架构**：
   - LeNet：CNN的开山之作
   - AlexNet：开启深度学习时代
   - VGGNet：小卷积核，深度网络
   - ResNet：残差连接，可训练极深网络

5. **CNN设计原则**：
   - 从浅到深，逐步提取高级特征
   - 空间降维，通道增加
   - 使用残差连接和批归一化

### 最佳实践

1. **卷积核选择**：
   - 默认使用3×3卷积核
   - 第一层可以使用较大卷积核（7×7）
   - 使用1×1卷积进行降维/升维

2. **池化策略**：
   - 使用2×2最大池化进行下采样
   - 网络末端使用全局平均池化替代全连接层

3. **网络深度**：
   - 浅层网络（<20层）：直接堆叠
   - 深层网络（>30层）：使用残差连接

4. **正则化**：
   - 使用Dropout防止过拟合
   - 使用批归一化稳定训练
   - 使用数据增强扩大训练集

### 下一步学习

掌握了本章内容后，建议继续学习：
- 目标检测（R-CNN、YOLO、SSD）
- 图像分割（FCN、U-Net、Mask R-CNN）
- 生成模型（GAN、VAE）
- 迁移学习和微调
- 可视化CNN特征图和卷积核

通过系统学习这些内容，你将能够使用CNN解决各种复杂的计算机视觉问题。

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-01T17:12:40.830055900Z",
     "start_time": "2026-02-01T17:12:40.813915800Z"
    }
   },
   "source": [
    "# PyTorch张量统计运算学习笔记\n",
    "# 涵盖:求和、均值、方差、最大最小值、排序、去重等操作\n",
    "import torch\n",
    "from sympy.abc import Q"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T17:12:40.861117200Z",
     "start_time": "2026-02-01T17:12:40.840693800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建测试张量\n",
    "# shape:(3,2,4) 可理解为3个2x4的矩阵\n",
    "# .float()转换为float32类型,因为统计运算通常需要浮点数\n",
    "# 应用:用于测试多维张量上的统计操作\n",
    "tensor1 = torch.randint(1, 10, (3, 2, 4)).float()\n",
    "print(tensor1)"
   ],
   "id": "cdea80b1c988a491",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5., 5., 3., 2.],\n",
      "         [7., 9., 6., 3.]],\n",
      "\n",
      "        [[7., 2., 3., 8.],\n",
      "         [2., 2., 4., 7.]],\n",
      "\n",
      "        [[3., 6., 7., 5.],\n",
      "         [6., 5., 4., 4.]]])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T17:12:40.877894800Z",
     "start_time": "2026-02-01T17:12:40.861117200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sum求和运算\n",
    "# .sum(): 对所有元素求和,返回标量\n",
    "# .sum(dim=k): 沿着第k维求和,该维度被消除\n",
    "# .sum(dim=(i,j)): 沿着多个维度求和\n",
    "# 应用:计算总损失、batch内求和、注意力权重归一化\n",
    "\n",
    "# 示例:tensor1.shape=(3,2,4), 共24个元素\n",
    "print(tensor1.sum())  # 全局求和:所有24个数相加\n",
    "\n",
    "# dim=0求和:沿着第0维(3个矩阵)求和\n",
    "# 结果:3个(2,4)矩阵对应位置相加→(2,4)\n",
    "# 理解:(3,2,4)→消除dim0→(2,4)\n",
    "print(tensor1.sum(dim=0))  # shape:(2,4)\n",
    "\n",
    "# dim=(0,2)求和:同时沿着0和2维求和\n",
    "# 结果:(3,2,4)→消除dim0和dim2→(2,)\n",
    "# 计算:对于结果的每一行,将所有3个矩阵的该行的4个元素都加起来\n",
    "print(tensor1.sum(dim=(0, 2)))  # shape:(2,)"
   ],
   "id": "4e382cf103d59789",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(115.)\n",
      "tensor([[15., 13., 13., 15.],\n",
      "        [15., 16., 14., 14.]])\n",
      "tensor([56., 59.])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T17:12:40.900588900Z",
     "start_time": "2026-02-01T17:12:40.879899900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# mean求均值\n",
    "# 用法与sum相同,但返回的是平均值\n",
    "# 公式:mean = sum / count\n",
    "# 应用:batch平均损失、均值池化(Global Average Pooling)\n",
    "\n",
    "print(tensor1.mean())  # 全局均值:sum(24个元素)/24\n",
    "\n",
    "# dim=0均值:沿着0维求平均\n",
    "# 计算:3个(2,4)矩阵对应位置的3个值求平均\n",
    "print(tensor1.mean(dim=0))  # shape:(2,4)\n",
    "\n",
    "# dim=(0,2)均值:同时沿着0和2维求平均\n",
    "# 计算:结果每个元素是3*4=12个数的平均值\n",
    "print(tensor1.mean(dim=(0, 2)))  # shape:(2,)"
   ],
   "id": "62bf9bd71bc6e200",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7917)\n",
      "tensor([[5.0000, 4.3333, 4.3333, 5.0000],\n",
      "        [5.0000, 5.3333, 4.6667, 4.6667]])\n",
      "tensor([4.6667, 4.9167])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T17:12:40.924663600Z",
     "start_time": "2026-02-01T17:12:40.902293200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# std求标准差\n",
    "# 标准差衡量数据的离散程度\n",
    "# 公式:std = sqrt(mean((x - mean(x))^2))\n",
    "# 应用:Batch Normalization、梯度裁剪阈值设置、特征标准化\n",
    "\n",
    "print(tensor1.std())  # 全局标准差\n",
    "\n",
    "# dim=0标准差:每个位置上3个值的标准差\n",
    "# 示例:tensor1[:,0,0]的3个值的标准差→结果[0,0]\n",
    "print(tensor1.std(dim=0))  # shape:(2,4)\n",
    "\n",
    "# dim=(0,2)标准差:\n",
    "print(tensor1.std(dim=(0, 2)))  # shape:(2,)"
   ],
   "id": "c27a6f667649e188",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0637)\n",
      "tensor([[2.0000, 2.0817, 2.3094, 3.0000],\n",
      "        [2.6458, 3.5119, 1.1547, 2.0817]])\n",
      "tensor([2.0597, 2.1515])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T17:12:40.947387300Z",
     "start_time": "2026-02-01T17:12:40.926666700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# max、min求最大最小值对应位置的3个值求平均\n",
    "print(tensor1.mean(dim=0))  # shape:(2,4)\n",
    "\n",
    "# dim=(0,2)均值:同时沿着0和2维求平均\n",
    "# 计算:结果每个元素是3*4=12个数的平均值\n",
    "print(tensor1.mean(dim=(0, 2)))  # shape:(2,)\n",
    "# std求标准差\n",
    "# 标准差衡量数据的离散程度\n",
    "# 公式:std = sqrt(mean((x - mean(x))^2))\n",
    "# 应用:Batch Normalization、梯度裁剪阈值设置、特征标准化\n",
    "\n",
    "# .max(): 返回单个标量(全局最大值)\n",
    "# .max(dim=k): 返回(values, indices)两个张量\n",
    "#   - values: 每个位置的最大值\n",
    "#   - indices: 最大值在dim=k维度上的索引位置\n",
    "# 应用:分类任务取预测类别、池化层、TopK准确率\n",
    "\n",
    "print(tensor1.max())  # 全局最大值(单个数)\n",
    "print(tensor1.min())  # 全局最小值(单个数)\n",
    "\n",
    "# dim=0最大值:\n",
    "# values[i,j]: 3个矩阵中位置(i,j)的最大值\n",
    "# indices[i,j]: 该最大值来自第几个矩阵(0/1/2)\n",
    "# 示例:若values[0,1]=7且indices[0,1]=1, 表示tensor1[1,0,1]=7是最大的\n",
    "print(tensor1.max(dim=0))  # 返回values(2,4)和indices(2,4)\n",
    "\n",
    "# dim=0最小值:逻辑同max\n",
    "print(tensor1.min(dim=0))  # 返回values(2,4)和indices(2,4)"
   ],
   "id": "469baa5b39552de0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.0000, 4.3333, 4.3333, 5.0000],\n",
      "        [5.0000, 5.3333, 4.6667, 4.6667]])\n",
      "tensor([4.6667, 4.9167])\n",
      "tensor(9.)\n",
      "tensor(2.)\n",
      "torch.return_types.max(\n",
      "values=tensor([[7., 6., 7., 8.],\n",
      "        [7., 9., 6., 7.]]),\n",
      "indices=tensor([[1, 2, 2, 1],\n",
      "        [0, 0, 0, 1]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[3., 2., 3., 2.],\n",
      "        [2., 2., 4., 3.]]),\n",
      "indices=tensor([[2, 1, 0, 0],\n",
      "        [1, 1, 1, 0]]))\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T17:12:40.965938700Z",
     "start_time": "2026-02-01T17:12:40.948393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# argmin求最小值的索引位置\n",
    "# 将张量展平为一维后,返回最小元素的位置索引\n",
    "# 示例:tensor1共(3,2,4)=24个元素,展平后索引为0-23\n",
    "# 返回Tensor(22)表示最小值在第22个位置(从0开始)\n",
    "# 对应关系:索引22 → (22//8, 22%8//4, 22%4) = (2,2,2) → tensor1[2,2,2]\n",
    "# 应用:查找极值位置、负样本挖掘\n",
    "print(tensor1.argmin())  # 返回展平后的一维索引"
   ],
   "id": "4da96d592e2534ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T17:12:40.986004800Z",
     "start_time": "2026-02-01T17:12:40.967972400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# unique去重\n",
    "# 返回排序后的唯一值列表\n",
    "# 示例:[1,3,2,3,1] → [1,2,3]\n",
    "# 应用:统计类别数、检查标签范围、数据探索性分析\n",
    "print(torch.unique(tensor1))  # 返回[1,2,3,4,5,6,7,8,9](排序)"
   ],
   "id": "7f0b1701943bd45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T17:12:41.009006200Z",
     "start_time": "2026-02-01T17:12:40.988004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sort排序\n",
    "# 默认沿最后一个维度升序排序\n",
    "# 返回(values, indices):\n",
    "#   - values: 排序后的张量\n",
    "#   - indices: 原始元素在排序前的索引位置\n",
    "# 应用:TopK选择、排序池化、中位数计算\n",
    "\n",
    "# 示例:tensor1.shape=(3,2,4),沿最后一维(4个元素)排序\n",
    "# 结果:每个(2,4)矩阵的每一行的四个元素升序排列\n",
    "# indices记录排序后元素在原行中的位置\n",
    "# 如果原行=[5,2,8,3],排序后=[2,3,5,8],indices=[1,3,0,2]\n",
    "print(tensor1.sort())  # 默认dim=-1(最后一维)"
   ],
   "id": "2dbd042b10e68e75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.sort(\n",
      "values=tensor([[[2., 3., 5., 5.],\n",
      "         [3., 6., 7., 9.]],\n",
      "\n",
      "        [[2., 3., 7., 8.],\n",
      "         [2., 2., 4., 7.]],\n",
      "\n",
      "        [[3., 5., 6., 7.],\n",
      "         [4., 4., 5., 6.]]]),\n",
      "indices=tensor([[[3, 2, 0, 1],\n",
      "         [3, 2, 0, 1]],\n",
      "\n",
      "        [[1, 2, 0, 3],\n",
      "         [0, 1, 2, 3]],\n",
      "\n",
      "        [[0, 3, 1, 2],\n",
      "         [2, 3, 1, 0]]]))\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

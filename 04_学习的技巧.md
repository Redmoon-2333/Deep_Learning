# 第4章 学习的技巧

## 本章导读

在前面的章节中，我们学习了神经网络的基本结构、损失函数、梯度计算和反向传播算法。但是，仅仅掌握这些基础知识还不足以训练出高性能的神经网络。本章将介绍神经网络训练中的各种实用技巧，这些技巧能够显著提升模型的性能和训练效率。

**学习目标**：
- 理解深度神经网络的训练难点
- 掌握各种优化算法的原理和应用场景
- 理解权重初始化的重要性
- 掌握 Batch Normalization 和 Dropout 等正则化技术
- 能够选择合适的超参数

**学习路线**：
```
深度网络问题 → 优化算法 → 权重初始化 → 正则化技术
(梯度消失/爆炸)  (SGD→Adam)  (Xavier/He)  (BN/Dropout)
```

**核心问题**：
- 为什么深度网络难以训练？→ 梯度消失和梯度爆炸
- 如何加速训练收敛？→ 改进的优化算法
- 如何防止过拟合？→ 正则化技术

---

## 4.1 深度神经网络及其问题

### 4.1.1 深度学习

**深度神经网络的定义**：
- 深度神经网络是指具有多个隐藏层的神经网络
- "深度"指的是网络的层数，而非单层的神经元数量
- 通常认为超过3层隐藏层的网络就是深度网络

**深度网络的优势**：

1. **更强的表达能力**：
   - 深层网络能够表示更复杂的函数
   - 每增加一层，模型的表达能力呈指数级增长
   - 能够学习数据的层次化表示

2. **特征的层次化学习**：
   - 浅层：学习简单特征（边缘、纹理）
   - 中层：组合简单特征（形状、部件）
   - 深层：学习高级语义特征（物体、场景）

3. **参数效率更高**：
   - 相比浅层宽网络，深层窄网络参数更少
   - 能用更少的神经元达到相同的表达能力

**网络深度对比**：

| 网络类型 | 层数 | 特点 | 应用场景 |
|---------|------|------|---------|
| 浅层网络 | 1-2层 | 表达能力有限 | 简单分类问题 |
| 中等深度 | 3-10层 | 平衡性能和训练难度 | 一般图像识别 |
| 深层网络 | 10层以上 | 强大表达能力，训练困难 | 复杂视觉任务 |
| 超深网络 | 50层以上 | 需要特殊技巧（ResNet） | ImageNet等大规模任务 |

### 4.1.2 梯度消失和梯度爆炸

**问题描述**：
在深度神经网络的训练过程中，梯度在反向传播时可能会出现两个极端情况：
- **梯度消失**（Gradient Vanishing）：梯度逐层衰减，最终接近于0
- **梯度爆炸**（Gradient Exploding）：梯度逐层放大，最终变得极大

**梯度消失的原因**：

1. **激活函数的饱和**：
   - Sigmoid 和 Tanh 的导数在输入绝对值较大时接近0
   - 例如：sigmoid'(x) = σ(x)(1-σ(x))，当 x 很大或很小时，导数接近0
   - 多层网络中，梯度相乘导致指数级衰减

2. **权重过小**：
   - 如果权重初始化过小，梯度会逐层缩小
   - 每经过一层，梯度乘以一个小于1的数

3. **网络过深**：
   - 层数越多，梯度消失越严重
   - 前面几层几乎学不到任何东西

**梯度爆炸的原因**：

1. **权重过大**：
   - 权重初始化过大，梯度会逐层放大
   - 每经过一层，梯度乘以一个大于1的数

2. **学习率过大**：
   - 参数更新步长过大
   - 导致参数振荡或发散

**数学分析**（简化版）：

考虑一个 L 层网络，第 l 层的梯度为：
$$
\frac{\partial L}{\partial W^l} = \frac{\partial L}{\partial a^L} \times \frac{\partial a^L}{\partial a^{L-1}} \times ... \times \frac{\partial a^{l+1}}{\partial a^l} \times \frac{\partial a^l}{\partial W^l}
$$

如果每层的梯度都小于1（例如0.5），则：
$$
L 层网络：梯度 \approx (0.5)^L
$$

$$
10 层：梯度 \approx 0.001
$$

$$
20 层：梯度 \approx 0.000001
$$

**梯度消失/爆炸的表现**：

| 现象 | 梯度消失 | 梯度爆炸 |
|-----|---------|---------|
| 权重更新 | 几乎不变 | 巨大变化 |
| 损失变化 | 停滞不动 | NaN或Inf |
| 训练表现 | 无法学习 | 训练不稳定 |
| 影响层次 | 前面几层 | 所有层 |

**直观理解**：
- **梯度消失**：像传话游戏，信息经过多人传递后，最初的信息几乎丢失
- **梯度爆炸**：像雪崩，小的扰动经过多次放大后变成灾难

**解决方案预览**（后续章节详细介绍）：
1. 更好的激活函数（ReLU）
2. 合适的权重初始化（Xavier、He初始化）
3. Batch Normalization
4. 残差连接（ResNet）
5. 梯度裁剪（针对梯度爆炸）

---

## 4.2 更新参数的方法优化

### 4.2.1 SGD的缺点

**标准SGD（Stochastic Gradient Descent）**：

最简单的参数更新规则：
$$
W \leftarrow W - \eta \times \frac{\partial L}{\partial W}
$$

其中：
- W：权重参数
- η：学习率
- ∂L/∂W：损失函数关于权重的梯度

**SGD的主要缺点**：

1. **学习率难以选择**：
   - 学习率过大：训练不稳定，可能发散
   - 学习率过小：收敛速度慢
   - 不同参数可能需要不同的学习率

2. **容易陷入局部最优**：
   - 在非凸优化问题中，容易卡在鞍点
   - 鞍点：某些方向是最小值，其他方向是最大值

3. **在平坦区域收敛慢**：
   - 损失函数的梯度很小时，更新步长也很小
   - 需要很长时间才能走出平坦区域

4. **对不同方向的敏感度不一致**：
   - 在陡峭方向振荡
   - 在平缓方向前进缓慢

**直观比喻**：
- SGD 像一个没有记忆的小球，每次只根据当前位置的坡度滚动
- 遇到之字形山谷会左右摇摆，前进缓慢

**代码实现**（来自 `common/optimizer.py`）：

```python
class SFGD:
    """
    随机梯度下降优化器 (Stochastic Gradient Descent)
    
    Parameters
    ----------
    lr : float
        学习率，控制每次更新的步长（默认0.01）
    """
    def __init__(self, lr=0.01):
        self.lr = lr  # 学习率
    
    def update(self, params, grads):
        """
        参数更新
        
        Parameters
        ----------
        params : dict
            参数字典，如 {'W1': ndarray, 'b1': ndarray, ...}
        grads : dict
            梯度字典，键与params对应
        """
        # 遍历所有参数，按公式 W = W - lr * grad 更新
        for key in params.keys():
            params[key] -= self.lr * grads[key]
```

**代码说明**：
- 极简实现：只需保存学习率 `lr`
- `update` 方法：遍历所有参数，按公式直接更新
- 无状态保存：每次更新都是独立的

### 4.2.2 Momentum

**Momentum（动量）算法**：

Momentum 引入了“速度”的概念，模拟物理学中的动量。

**算法公式**：

$$
v \leftarrow \mu v - \eta \times \frac{\partial L}{\partial W}
$$

$$
W \leftarrow W + v
$$

其中：
- v：速度（velocity）
- μ：动量系数（momentum），通常取0.9
- η：学习率

**核心思想**：
- 不仅考虑当前梯度，还考虑历史梯度
- 梯度方向一致时，速度累积加快
- 梯度方向变化时，速度减缓

**Momentum 的优势**：

1. **加速收敛**：
   - 在一致的方向上积累速度
   - 比纯SGD更快到达最优点

2. **减少振荡**：
   - 历史动量抵消了振荡方向的梯度
   - 在之字形路径上更加平滑

3. **逃离局部最优**：
   - 积累的动量可以帮助越过小的局部最优点
   - 增强了探索能力

**物理类比**：
- 像一个滚动的小球，具有惯性
- 下坡时越滚越快
- 即使遇到小的上坡也能继续前进

**参数说明**：
- μ = 0：退化为普通SGD
- μ 接近1：更重视历史梯度
- 常用值：0.9 或 0.99
- **默认推荐**：μ = 0.9，学习率 η = 0.01

**代码实现**（来自 `common/optimizer.py`）：

```python
class Momentum:
    """
    动量优化器
    
    Parameters
    ----------
    lr : float
        学习率（默认0.01）
    momentum : float
        动量系数μ，控制历史速度的保留比例（默认0.9）
    """
    def __init__(self, lr=0.01, momentum=0.9):
        self.lr = lr              # 学习率
        self.momentum = momentum  # 动量系数
        self.v = None             # 速度字典，首次update时初始化
    
    def update(self, params, grads):
        # 首次调用时，为每个参数初始化速度为0
        if self.v is None:
            self.v = {}
            for key in params.keys():
                self.v[key] = np.zeros_like(params[key])
        
        # 遍历所有参数进行更新
        for key in params.keys():
            # 核心公式: v = μ*v - lr*grad
            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]
            # 用速度更新参数: W = W + v
            params[key] += self.v[key]
```

**代码说明**：
- `self.v`：保存每个参数的速度，首次调用时初始化为0
- 更新逻辑：先计算速度（动量积累 + 当前梯度），再用速度更新参数
- `momentum` 为0.9意味着保留90%的历史速度

### 4.2.3 学习率衰减

**学习率衰减（Learning Rate Decay）**：

在训练过程中逐渐降低学习率，而不是使用固定学习率。

**为什么需要学习率衰减**：

1. **训练初期**：
   - 参数距离最优点较远
   - 需要较大学习率快速接近最优点

2. **训练后期**：
   - 参数已经接近最优点
   - 大学习率会导致参数在最优点附近振荡
   - 需要小学习率进行精细调整

**常见的学习率衰减策略**：

1. **阶段衰减（Step Decay）**：
$$
   \eta(t) = \eta_0 \times \gamma^{\lfloor t/k \rfloor}
$$
- 每 k 个epoch，学习率乘以 γ（如0.5）
   - 优点：简单易实现
   - 缺点：需要手动设置衰减时机

2. **梯度间隔衰减（Interval Decay）**
$$
\eta(epoch) = \begin{cases}
\eta_0, & epoch < epoch_1 \\
\eta_0 \times \gamma, & epoch_1 \leq epoch < epoch_2 \\
\eta_0 \times \gamma^2, & epoch_2 \leq epoch < epoch_3 \\
...
\end{cases}
$$

   **具体示例**：使学习率在 epoch 达到 [10, 50, 200] 时衰减为之前的 0.7：
$$
\eta(epoch) = \begin{cases}
\eta_0, & epoch < 10 \\
\eta_0 \times 0.7, & 10 \leq epoch < 50 \\
\eta_0 \times 0.7^2, & 50 \leq epoch < 200 \\
\eta_0 \times 0.7^3, & epoch \geq 200
\end{cases}
$$

   **特点**：
   - **灵活的衰减时机**：可以根据训练进度自定义衰减点，在训练出现瓶颈时手动触发衰减
   - **稳定的训练阶段**：在两次衰减之间保持学习率不变，给模型充分时间收敛
   - **易于控制和调试**：衰减点和衰减系数都很直观，便于理解和复现实验
   - **适用场景**：长期训练（几百个 epoch）、需要分阶段调整策略、根据验证集性能动态决定衰减时机

   **效果分析**：
   - 优化轨迹：初期大学习率快速接近最优区域，后期小学习率精细调整，最终稳定收敛
   - 学习率变化：在指定 epoch 处出现明显的阶梯式下降，每个平台期内保持恒定

3. **指数衰减（Exponential Decay）**：
$$
\eta(t) = \eta_0 \times e^{-\lambda t}
$$
   - 学习率平滑连续下降
   - λ 控制衰减速度

4. **多项式衰减（Polynomial Decay）**：
$$
\eta(t) = \eta_0 \times (1 - t/T)^p
$$
   - T 是总训练步数
   - p 通常取0.5或1

5. **余弦退火（Cosine Annealing）**：
$$
\eta(t) = \eta_{min} + (\eta_0 - \eta_{min}) \times \frac{1 + \cos(\pi t/T)}{2}
$$
   - 学习率按余弦函数下降
   - 常用于现代深度学习

**与连续衰减的对比**：

| 特性 | 梯度间隔衰减 | 指数/余弦衰减 |
|-----|------------|-------------|
| 学习率变化 | 阶梯式，突变 | 平滑连续 |
| 训练阶段 | 明确划分 | 无明确边界 |
| 调试难度 | 容易 | 较难 |
| 灵活性 | 高（可自定义衰减点） | 低（需设置衰减速度） |
| 适用场景 | 长期训练，分阶段策略 | 一般训练 |

**学习率调度示例**：

| Epoch | Step Decay (γ=0.5, k=10) | Interval Decay ([10,50,200], γ=0.7) | Exponential (λ=0.1) | Cosine |
|-------|-------------------------|----------------------------------|---------------------|--------|
| 0-9   | η₀ | η₀ | η₀ | η₀ |
| 10-19 | 0.5η₀ | 0.7η₀ | 0.37η₀ | 下降中 |
| 20-29 | 0.25η₀ | 0.7η₀ | 0.14η₀ | 下降中 |
| 50-199 | 0.0625η₀ | 0.49η₀ | 接近0 | 接近η_min |
| 200+ | - | 0.343η₀ | 接近0 | η_min |

**实践建议**：
- 初始学习率：0.01 ~ 0.1
- 衰减因子：0.1 ~ 0.5
- 也可以根据验证集损失动态调整

### 4.2.4 AdaGrad

**AdaGrad（Adaptive Gradient）算法**：

AdaGrad 为每个参数自适应地调整学习率。

**算法公式**：
$$
h \leftarrow h + \left(\frac{\partial L}{\partial W}\right)^2 \quad (元素级平方)
$$

$$
W \leftarrow W - \eta \times \frac{\partial L}{\partial W} / (\sqrt{h} + \varepsilon)
$$
其中：
- h：梯度平方和的累积
- ε：防止除零的小常数（代码中为 1e-7）
- √(h) + ε：对每个参数独立调整学习率

**核心思想**：
- 梯度大的参数 → h 大 → 学习率小 → 更新步长小
- 梯度小的参数 → h 小 → 学习率大 → 更新步长大
- 实现了参数级别的自适应学习率

**AdaGrad 的优势**：

1. **自动调整学习率**：
   - 不需要手动调整学习率
   - 每个参数有独立的学习率

2. **适合稀疏梯度**：
   - 对于不经常更新的参数给予更大的学习率
   - 特别适合处理稀疏数据（如NLP中的词向量）

3. **减少手动调参**：
   - 对初始学习率不太敏感
   - 训练更加稳定

**AdaGrad 的缺点**：

1. **学习率单调递减**：
   - h 不断累积，只增不减
   - 学习率会持续下降
   - 训练后期学习率可能过小，导致学习停止

2. **需要手动设置初始学习率**：
   - 虽然有自适应，但初始学习率仍然重要

**参数设置建议**：
- **初始学习率 η**：0.01（默认推荐）
- **防止除零 ε**：1e-7（代码实现值）

**适用场景**：
- 稀疏数据
- 需要不同参数有不同学习率
- 训练步数不太多的情况

**代码实现**（来自 `common/optimizer.py`）：

```python
class AdaGrad:
    """
    AdaGrad优化器（Adaptive Gradient）
    
    Parameters
    ----------
    lr : float
        初始学习率（默认0.01）
    """
    def __init__(self, lr=0.01):
        self.lr = lr   # 初始学习率
        self.h = None  # 梯度平方累积量，首次update时初始化

    def update(self, params, grads):
        # 首次调用时，为每个参数初始化累积量h为0
        if self.h is None:
            self.h = {}
            for key in params.keys():
                self.h[key] = np.zeros_like(params[key])

        for key in params.keys():
            # 累积历史梯度的平方: h = h + grad²
            self.h[key] += grads[key] * grads[key]
            # 自适应更新: W = W - lr * grad / √h
            # 1e-7 防止除零错误
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```

**代码说明**：
- `self.h`：保存每个参数的梯度平方累积量
- 累积逻辑：`h += grad * grad`，只增不减
- 自适应学习率：`lr / (sqrt(h) + 1e-7)`，h 越大，有效学习率越小
- **关键点**：防止除零项 `1e-7` 在分母内

### 4.2.5 RMSProp

**RMSProp（Root Mean Square Propagation）算法**：

RMSProp 是对 AdaGrad 的改进，解决了学习率单调递减的问题。

**算法公式**：
$$
h \leftarrow \rho h + (1-\rho)\left(\frac{\partial L}{\partial W}\right)^2 \quad (指数移动平均)
$$

$$
W \leftarrow W - \eta \times \frac{\partial L}{\partial W} / (\sqrt{h} + \varepsilon)
$$
其中：
- ρ：衰减率（decay），通常取0.9或0.99
- h：梯度平方的指数移动平均
- ε：防止除零的小常数（1e-7）
- 其他符号与 AdaGrad 相同

**核心改进**：
- 使用**指数移动平均**代替累积和
- 只关注最近的梯度，遗忘远古的梯度
- 学习率不会无限下降

**RMSProp vs AdaGrad**：

| 特性 | AdaGrad | RMSProp |
|-----|---------|---------|
| 梯度累积 | 累积所有历史梯度 | 指数移动平均 |
| 学习率趋势 | 单调递减 | 可上可下 |
| 长期训练 | 学习率过小 | 保持适当学习率 |
| 适用性 | 短期训练 | 长期训练 |

**RMSProp 的优势**：

1. **克服学习率递减问题**：
   - 使用移动平均，遗忘远古梯度
   - 适合长时间训练

2. **保持自适应性**：
   - 继承了 AdaGrad 的参数级自适应
   - 不同参数仍有不同的有效学习率

3. **在非凸优化中表现好**：
   - 能够逃离鞍点
   - 在深度学习中广泛使用

**参数设置建议**：
- **学习率 η**：0.01（默认推荐）
- **衰减率 ρ**：0.9（默认推荐）或 0.99
- **防止除零 ε**：1e-7（代码实现值）

**直观理解**：
- AdaGrad 像一个记仇的人，永远记得所有的梯度
- RMSProp 像一个健忘的人，只记得最近的梯度

**代码实现**（来自 `common/optimizer.py`）：

```python
class RMSProp:
    """
    RMSProp优化器（Root Mean Square Propagation）
    
    Parameters
    ----------
    lr : float
        学习率（默认0.01）
    decay : float
        衰减率，控制历史信息的保留比例（默认0.9）
    """
    def __init__(self, lr=0.01, decay=0.9):
        self.lr = lr       # 学习率
        self.decay = decay # 衰减率
        self.h = None      # 梯度平方的指数移动平均

    def update(self, params, grads):
        # 首次调用时初始化h
        if self.h is None:
            self.h = {}
            for key in params.keys():
                self.h[key] = np.zeros_like(params[key])

        for key in params.keys():
            # 指数移动平均: h = decay*h + (1-decay)*grad²
            self.h[key] *= self.decay
            self.h[key] += (1 - self.decay) * grads[key] * grads[key]
            # 自适应更新: W = W - lr * grad / √h
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```

**代码说明**：
- `self.h`：保存梯度平方的指数移动平均
- 更新逻辑：`h = 0.9*h + 0.1*grad²`（decay=0.9时）
- 与 AdaGrad 的关键区别：使用指数移动平均而非累加，h 可以增加也可以减少
- `decay` 控制历史影响：0.9意味着保留90%历史 + 10%当前

### 4.2.6 Adam

**Adam（Adaptive Moment Estimation）算法**：

Adam 结合了 Momentum 和 RMSProp 的优点，是目前最流行的优化算法之一。

**算法公式**：
$$
一阶矩估计（动量）：v \leftarrow \beta_1 v + (1-\beta_1) \times \frac{\partial L}{\partial W}
$$

$$
二阶矩估计（梯度平方）：h \leftarrow \beta_2 h + (1-\beta_2) \times \left(\frac{\partial L}{\partial W}\right)^2
$$

$$
偏差修正后的学习率：\eta_t \leftarrow \eta \times \frac{\sqrt{1 - \beta_2^t}}{1 - \beta_1^t}
$$

$$
参数更新：W \leftarrow W - \eta_t \times \frac{v}{\sqrt{h} + \varepsilon}
$$
其中：
- v：一阶矩（梯度的指数移动平均）
- h：二阶矩（梯度平方的指数移动平均）
- β₁：一阶矩衰减率（alpha1），通常取0.9
- β₂：二阶矩衰减率（alpha2），通常取0.999
- t：时间步
- η：初始学习率
- η_t：偏差修正后的学习率
- ε：防止除零（1e-7）

**核心特点**：

1. **偏差修正机制**：
   - 初始阶段 v 和 h 都是0，前几步的移动平均会严重偏向0
   - 修正因子 √(1-β₂^t)/(1-β₁^t) 在初期较大，补偿这种偏差
   - 随着 t 增大，修正因子趋近于1，影响消失

2. **结合动量和自适应**：
   - v：像 Momentum 一样累积梯度，加速收敛
   - h：像 RMSProp 一样调整学习率，自适应地缩放

**Adam 的优势**：

1. **结合多种优点**：
   - 像 Momentum 一样利用历史梯度加速收敛
   - 像 RMSProp 一样自适应调整学习率
   - 加入偏差修正，避免初期学习率过小

2. **超参数鲁棒**：
   - 对超参数选择不敏感
   - 默认参数在大多数问题上表现良好

3. **广泛适用**：
   - 适合大规模数据和高维参数
   - 适合非平稳目标
   - 适合稀疏梯度

**Adam vs 其他算法**：

| 算法 | 动量 | 自适应学习率 | 偏差修正 | 适用性 |
|-----|------|------------|---------|--------|
| SGD | ✗ | ✗ | ✗ | 一般 |
| Momentum | ✓ | ✗ | ✗ | 较好 |
| AdaGrad | ✗ | ✓ | ✗ | 稀疏数据 |
| RMSProp | ✗ | ✓ | ✗ | 较广 |
| Adam | ✓ | ✓ | ✓ | 最广 |

**参数设置建议**：
- **学习率 η**：0.01（代码默认值，实践中常用 0.001）
- **一阶矩衰减率 β₁**：0.9（默认推荐）
- **二阶矩衰减率 β₂**：0.999（默认推荐）
- **防止除零 ε**：1e-7（代码实现值）

**使用建议**：
- **首选 Adam**：作为默认优化器
- **SGD + Momentum**：某些情况下泛化性能更好
- **实验对比**：最好在具体问题上对比测试

**实践经验**：
- Adam 通常收敛更快
- SGD + Momentum 有时最终性能略好
- Adam 可能在某些任务上过拟合

**代码实现**（来自 `common/optimizer.py`）：

```python
class Adam:
    """
    Adam优化器（Adaptive Moment Estimation）
    
    Parameters
    ----------
    lr : float
        学习率（默认0.01）
    alpha1 : float
        一阶矩衰减率β₁（默认0.9）
    alpha2 : float
        二阶矩衰减率β₂（默认0.999）
    """
    def __init__(self, lr=0.01, alpha1=0.9, alpha2=0.999):
        self.lr = lr         # 学习率
        self.alpha1 = alpha1 # 一阶矩衰减率(β₁)
        self.alpha2 = alpha2 # 二阶矩衰减率(β₂)
        self.v = None        # 一阶矩：梯度的指数移动平均
        self.h = None        # 二阶矩：梯度平方的指数移动平均
        self.t = 0           # 时间步，用于偏差修正

    def update(self, params, grads):
        # 首次调用时初始化一阶矩v
        if self.v is None:
            self.v = {}
            for key in params.keys():
                self.v[key] = np.zeros_like(params[key])

        # 首次调用时初始化二阶矩h
        if self.h is None:
            self.h = {}
            for key in params.keys():
                self.h[key] = np.zeros_like(params[key])

        # 时间步+1，用于偏差修正
        self.t += 1
        # 偏差修正后的学习率: lr_t = lr * √(1-β₂^t) / (1-β₁^t)
        lr_t = self.lr * np.sqrt(1 - self.alpha2**self.t) / (1 - self.alpha1**self.t)
        
        for key in params.keys():
            # 更新一阶矩: v = β₁*v + (1-β₁)*grad
            self.v[key] = self.alpha1 * self.v[key] + (1 - self.alpha1) * grads[key]
            # 更新二阶矩: h = β₂*h + (1-β₂)*grad²
            self.h[key] = self.alpha2 * self.h[key] + (1 - self.alpha2) * grads[key] * grads[key]
            # 参数更新: W = W - lr_t * v / √h
            params[key] -= lr_t * self.v[key] / (np.sqrt(self.h[key]) + 1e-7)
```

**代码说明**：

1. **三个状态变量**：
   - `self.v`：一阶矩（梯度的移动平均，类似 Momentum）
   - `self.h`：二阶矩（梯度平方的移动平均，类似 RMSProp）
   - `self.t`：时间步，用于计算偏差修正因子

2. **偏差修正**：
   - 公式：`lr_t = lr * sqrt(1-β₂^t) / (1-β₁^t)`
   - 初期（t小）：lr_t 较大，补偿 v 和 h 偏向0的问题
   - 后期（t大）：lr_t 趋近于 lr

3. **更新步骤**：
   - 更新一阶矩 v：累积梯度动量
   - 更新二阶矩 h：累积梯度平方
   - 参数更新：用修正后的学习率和自适应缩放

4. **关键细节**：
   - 代码中直接计算 `lr_t`，不需要分别修正 v 和 h
   - `alpha1` 和 `alpha2` 分别对应文档中的 β₁ 和 β₂
   - 防止除零项 `1e-7` 在分母内

**与文档公式的对应**：
- 文档：分步计算 m̂ 和 v̂，然后更新
- 代码：直接计算 lr_t，用 v 和 h 更新（数学等价，更高效）

### 优化算法总结

**算法演进路线**：
```
SGD → Momentum → AdaGrad → RMSProp → Adam
(基础)  (加速)    (自适应)   (改进)    (集大成)
```

**选择指南**：

| 场景 | 推荐算法 | 原因 |
|-----|---------|------|
| 默认选择 | Adam | 综合性能最好 |
| 追求最佳精度 | SGD + Momentum | 泛化性能可能更好 |
| 稀疏数据 | AdaGrad | 专门为稀疏梯度设计 |
| 不确定 | Adam → SGD | 先用Adam快速收敛，再用SGD精调 |
| 学习率敏感 | Adam | 对超参数不敏感 |

### 优化器对比实验

**实验目的**：

通过在同一个优化问题上对比不同优化器的表现，直观理解各算法的收敛特点。

**目标函数**：
$$
f(x, y) = \frac{x^2}{20} + y^2
$$
这是一个椭圆形的损失函数曲面，最小值在 (0, 0) 处。x 方向更平缓，y 方向更陡峭。

**梯度计算**：
$$
\frac{\partial f}{\partial x} = \frac{x}{10}
$$

$$
\frac{\partial f}{\partial y} = 2y
$$
**完整代码**（来自 `ch05_optim/1_optimiazer_compare.py`）：

```python
import numpy as np
import matplotlib.pyplot as plt
from common.gradient import numerical_gradient
from collections import OrderedDict
from common.optimizer import *

# 定义目标函数 f(x,y) = 1/20 x^2 + y^2
def f(x, y):
    return x**2/20 + y**2

# 定义梯度计算方法，得到长度2的向量
def f_grad(x, y):
    return x/10, 2*y

# 定义初始位置
init_pos = (-7.0, 2.0)

# 定义参数和梯度
params = {}
grads = {}

# 定义优化器，指定学习率
optimizers = OrderedDict()
optimizers['SGD'] = SGD(lr=0.1)
optimizers['Momentum'] = Momentum(lr=0.1)
optimizers['AdaGrad'] = AdaGrad(lr=0.1)
optimizers['Adam'] = Adam(lr=0.1)

idx = 1

# 遍历优化器
for key in optimizers.keys():
    optimizer = optimizers[key]
    # 记录参数点更新历史
    x_history = []
    y_history = []
    # 参数初始化
    params['x'], params['y'] = init_pos[0], init_pos[1]
    for i in range(30):
        # 保存点坐标
        x_history.append(params['x'])
        y_history.append(params['y'])
        # 计算梯度
        grads['x'], grads['y'] = f_grad(params['x'], params['y'])
        # 参数更新
        optimizer.update(params, grads)

    # 画图
    x = np.arange(-10, 10, 0.01)
    y = np.arange(-5, 5, 0.01)
    X, Y = np.meshgrid(x, y)
    Z = f(X, Y)
    Z[Z > 7] = 0   # 截断
    # 定义子图
    plt.subplot(2, 2, idx)
    idx += 1
    # 绘制等高线
    plt.contourf(X, Y, Z)
    # 单独画出最小值点
    plt.plot(0, 0, '+')
    # 画出点轨迹曲线
    plt.plot(x_history, y_history, 'o-', color='red', markersize=2, label=key)
    plt.xlim(-10, 10)
    plt.ylim(-5, 5)
    plt.legend(loc='best')
plt.show()
```

**代码说明**：

1. **目标函数设计**：
   - `f(x,y) = x²/20 + y²`：椭圆形损失函数
   - x 方向更平缓（系数 1/20），y 方向更陡峭（系数 1）
   - 这种设计可以测试优化器在不同方向上的表现

2. **优化器对比**：
   - 所有优化器使用相同的学习率 lr=0.1
   - 从相同的起点 (-7.0, 2.0) 开始
   - 迭代 30 次，记录每次的位置

3. **可视化**：
   - 使用 2x2 子图展示四种优化器
   - 背景：损失函数的等高线图
   - 红色轨迹：优化器的距离路径
   - '+' 号：最优点 (0, 0)

**实验结果可视化**：

[优化器对比实验结果图](images/optimizer_comparison.png)

*预期结果分析**：

运行上述代码后，会生成 2×2 的子图对比，展示四种优化器在椭圆形损失函数上的优化轨迹：

**1. SGD（左上图）**：
- **轨迹特征**：之字形（锯齿状）路径
- **行为描述**：
  - 从起点 (-7, 2) 出发后，在 y 方向快速下降（因为 y 方向梯度大）
  - 在 x 方向移动缓慢（因为 x 方向梯度小，系数仅 1/20）
  - 路径呈现明显的左右振荡，像"之"字形曲折前进
  - 收敛速度慢，需要更多迭代才能接近最优点
- **问题根源**：固定学习率无法同时适应不同方向的曲率差异

**2. Momentum（右上图）**：
- **轨迹特征**：平滑的波浪形路径
- **行为描述**：
  - 初期仍有振荡，但振幅逐渐减小
  - 由于积累了历史梯度的动量，路径更加平滑
  - 不会因为单次梯度方向改变而剧烈转向
  - 在 x 方向上能保持持续的前进动力
  - 收敛速度明显快于 SGD
- **改进效果**：通过"惯性"减少了 SGD 的振荡问题

**3. AdaGrad（左下图）**：
- **轨迹特征**：较为直接的路径，几乎没有大幅振荡
- **行为描述**：
  - 初期在 y 方向快速下降后，学习率自动减小
  - 在 x 方向由于梯度始终较小，学习率保持较大
  - 自适应机制使得两个方向的步长更加均衡
  - 路径比 SGD 和 Momentum 都更直接
  - 能够快速找到合适的前进方向
- **自适应优势**：自动调整各方向的学习率，处理不同曲率

**4. Adam（右下图）**：
- **轨迹特征**：最平滑、最直接的路径
- **行为描述**：
  - 结合了 Momentum 的平滑性和 AdaGrad 的自适应性
  - 从起点出发后，迅速调整方向指向最优点
  - 路径几乎呈直线，振荡极小
  - 收敛速度最快，通常在最少的迭代次数内达到最优点
  - 偏差修正机制确保初期也能稳定前进
- **综合优势**：兼具动量积累和自适应学习率的双重优点

**四种优化器的直观对比**：

| 优化器 | 轨迹形状 | 振荡程度 | 收敛速度 | 关键特点 |
|--------|----------|----------|----------|----------|
| SGD | 之字形 | 严重 | 慢 | 基准算法，问题明显 |
| Momentum | 波浪形 | 中等 | 较快 | 减少振荡，保持动量 |
| AdaGrad | 较直接 | 轻微 | 快 | 自适应调整，路径直接 |
| Adam | 几乎直线 | 极小 | 最快 | 综合优势，表现最佳 |

**可视化要素说明**：
- **背景等高线**：颜色越深表示损失值越小，中心的深紫色区域是最优点附近
- **红色轨迹线**：优化器在参数空间中的移动路径，圆点表示每次迭代的位置
- **蓝色 '+' 号**：真实的最优点 (0, 0)，即损失函数的最小值点
- **椭圆形等高线**：反映了 x 方向（水平）和 y 方向（垂直）的不同曲率

*实验的深层价值**：

1. **可视化理解**：
   - 将抽象的数学公式转化为直观的运动轨迹
   - 清楚看到每种算法的行为模式和收敛特征
   - 理解"优化"的本质是在参数空间中寻找最优点的过程

2. **问题诊断**：
   - SGD 的之字形路径解释了为什么需要改进
   - 椭圆形等高线暴露了固定学习率的局限性
   - 不同方向的曲率差异是优化困难的根源

3. **算法改进的必要性**：
   - **Momentum 的价值**：通过历史梯度积累减少振荡，让优化过程更稳定
   - **自适应学习率的价值**：为不同参数分配不同的学习率，处理各向异性问题
   - **Adam 的综合优势**：同时解决振荡和学习率问题，实现最优收敛路径

4. **实践指导**：
   - 理解为什么 Adam 成为深度学习的默认选择
   - 认识到优化器的选择对训练效果的重要影响
   - 学会根据损失曲面特性选择合适的优化器


---

## 4.3 参数初始化

### 4.3.1 常数初始化

**全零初始化的问题**：

如果将所有权重初始化为相同的常数（如0），会出现严重问题：

```
W = [[0, 0, 0],
     [0, 0, 0],
     [0, 0, 0]]
```

**问题分析**：

1. **对称性无法打破**：
   - 所有神经元的输出完全相同
   - 反向传播时，所有神经元的梯度也相同
   - 权重更新后仍然完全相同

2. **神经元冗余**：
   - 相当于只有一个神经元在工作
   - 多个神经元失去了意义
   - 网络退化为线性模型

**直观理解**：
- 如果一群人起跑时站在同一位置，朝同一方向跑，永远保持队形
- 失去了神经网络的"多样性"

**正确做法**：
- 权重必须随机初始化
- 打破对称性，让每个神经元学习不同的特征

### 4.3.2 标准初始化

**随机初始化**：

最简单的随机初始化方法：
$$
W \sim N(0, \sigma^2) \quad 或 \quad W \sim U(-a, a)
$$
即从正态分布或均匀分布中随机采样。

**标准差的选择问题**：

1. **标准差过小**：
   - 权重接近0
   - 激活值很小
   - 梯度很小，学习缓慢
   - 容易出现梯度消失

2. **标准差过大**：
   - 权重过大
   - 激活值过大（可能饱和）
   - 梯度不稳定
   - 容易出现梯度爆炸

**实验现象**（以 Sigmoid 激活为例）：

| 初始化标准差 | 激活值分布 | 梯度情况 | 训练效果 |
|------------|-----------|---------|---------|
| 0.01 | 集中在0附近 | 很小 | 收敛慢 |
| 1.0 | 饱和在0或1 | 接近0 | 梯度消失 |
| 适中 | 均匀分布 | 合适 | 训练良好 |

**关键问题**：
如何选择合适的初始化标准差？ → 这就引出了 Xavier 和 He 初始化

### 4.3.3 正态分布初始化

**正态分布初始化的基本形式**：

```
W ~ N(0, σ²)
```

从均值为0、标准差为σ的正态分布中采样。

**为什么使用正态分布**：

1. **数学性质好**：
   - 中心极限定理：大量随机变量和趋向正态分布
   - 便于理论分析

2. **对称性**：
   - 均值为0，避免偏向某一侧
   - 正负值均衡

3. **可控性**：
   - 通过调整σ控制权重大小
   - 99.7%的值在 [-3σ, 3σ] 范围内

**标准差的设置**：

不同的初始化方法对应不同的σ：
- 标准正态分布：σ = 1（通常不好）
- Xavier初始化：σ = √(1/n_in)
- He初始化：σ = √(2/n_in)

其中 n_in 是输入神经元数量。

### 4.3.4 均匀分布初始化

**均匀分布初始化的基本形式**：

```
W ~ U(-a, a)
```

从区间 [-a, a] 的均匀分布中采样。

**均匀分布的特点**：

1. **严格的界限**：
   - 保证权重在 [-a, a] 范围内
   - 不会出现极端值

2. **与正态分布的关系**：
   - 均匀分布 U(-√3σ, √3σ) 的方差 = σ²
   - 可以转换为等价的正态分布

**范围的设置**：

- Xavier均匀分布：a = √(6/(n_in + n_out))
- He均匀分布：a = √(6/n_in)

**正态分布 vs 均匀分布**：

| 特性 | 正态分布 | 均匀分布 |
|-----|---------|---------|
| 值的范围 | 无界（理论上） | 有界 [-a, a] |
| 中间值概率 | 高 | 均等 |
| 极端值 | 小概率存在 | 不存在 |
| 使用频率 | 更常用 | 也常用 |

**实践中的选择**：
- 两者性能接近
- PyTorch 和 TensorFlow 都支持两种
- 正态分布稍微更常用

### 4.3.5 Xavier初始化（也叫Glorot初始化）

**Xavier 初始化的提出**：

由 Xavier Glorot 在2010年提出，针对 Sigmoid 和 Tanh 激活函数。

**核心思想**：
- 保持前向传播时，各层激活值的方差一致
- 保持反向传播时，各层梯度的方差一致

**Xavier 初始化公式**：

1. **正态分布版本**：
$$
W \sim N(0, \sigma^2)
$$

$$
\sigma = \sqrt{\frac{2}{n_{in} + n_{out}}}
$$
2. **均匀分布版本**：
   ```
   W ~ U(-a, a)
   a = √(6 / (n_in + n_out))
   ```

其中：
- n_in：输入维度（前一层神经元数）
- n_out：输出维度（当前层神经元数）

**数学推导（简化）**：

假设：
- 输入 x 的方差为 Var(x)
- 权重 W 初始化为方差 Var(W)
- 输出 y = Wx（忽略激活函数）

则输出方差：
$$
Var(y) = n_{in} \times Var(W) \times Var(x)
$$
为了保持 Var(y) = Var(x)，需要：
$$
Var(W) = \frac{1}{n_{in}}
$$
考虑反向传播，综合得到：
$$
Var(W) = \frac{2}{n_{in} + n_{out}}
$$
**Xavier 初始化的优势**：

1. **保持信号方差**：
   - 前向传播：激活值不会逐层衰减或放大
   - 反向传播：梯度不会消失或爆炸

2. **自动适应网络结构**：
   - 根据层的大小自动调整
   - 不需要手动调参

3. **训练稳定**：
   - 各层的学习速度相近
   - 收敛更快

**适用场景**：
- Sigmoid 激活函数
- Tanh 激活函数
- 不适合 ReLU（会导致方差减半）

### 4.3.6 He初始化（也叫Kaiming初始化）

**He 初始化的提出**：

由何恺明（Kaiming He）在2015年提出，专门针对 ReLU 激活函数。

**核心思想**：
- ReLU 会将负值置零，有效神经元数量减半
- 需要更大的初始化方差来补偿

**He 初始化公式**：

1. **正态分布版本**：
$$
W \sim N(0, \sigma^2)
$$

$$
\sigma = \sqrt{\frac{2}{n_{in}}}
$$
2. **均匀分布版本**：
$$
W \sim U(-a, a)
$$

$$
a = \sqrt{\frac{6}{n_{in}}}
$$
**与 Xavier 的区别**：

| 特性 | Xavier | He |
|-----|--------|-----|
| 适用激活函数 | Sigmoid/Tanh | ReLU/Leaky ReLU |
| 方差 | 2/(n_in+n_out) | 2/n_in |
| 补偿因子 | 无 | 考虑ReLU的影响 |

**数学推导（简化）**：

ReLU 激活函数：
$$
y = \max(0, x)
$$
如果 x 服从均值为0的对称分布：
- 约一半的值被置零
- 有效方差减半

为了补偿这个减半效应：
$$
Var(W) = \frac{2}{n_{in}} \quad (比Xavier的 1/n_{in} 大一倍)
$$
**He 初始化的优势**：

1. **专门为ReLU设计**：
   - 考虑了ReLU的非线性特性
   - 保持激活值方差稳定

2. **深度网络表现好**：
   - 在非常深的网络中（如ResNet）表现优异
   - 避免梯度消失

3. **简单有效**：
   - 只依赖于输入维度
   - 计算简单

**使用建议**：
- 使用 ReLU、Leaky ReLU、PReLU 时，选择 He 初始化
- 使用 Sigmoid、Tanh 时，选择 Xavier 初始化
- 现代深度学习中，ReLU + He 初始化是标配

**实践对比**：

| 网络深度 | 标准初始化 | Xavier | He |
|---------|-----------|--------|-----|
| 5层 | 可训练 | 好 | 最好 |
| 10层 | 困难 | 好 | 最好 |
| 50层 | 几乎不可能 | 勉强 | 好 |

---

## 4.4 正则化

### 4.4.1 Batch Normalization和直观标准化

**Batch Normalization（批标准化）**：

Batch Normalization（BN）是2015年提出的一项革命性技术，显著改善了深度网络的训练。

**核心思想**：
- 在每层的激活之前，对数据进行标准化
- 使每层的输入保持在合适的分布范围
- 类似于对输入数据进行标准化，但应用于每一层

**为什么需要 Batch Normalization**：

1. **内部协变量偏移（Internal Covariate Shift）**：
   - 训练过程中，前面层的参数更新导致后面层的输入分布不断变化
   - 每层都需要不断适应新的输入分布
   - 降低了训练效率

2. **梯度消失/爆炸**：
   - 激活值过大或过小都会影响梯度
   - BN 保持激活值在合理范围

3. **对初始化不敏感**：
   - 即使初始化不好，BN 也能调整到合适的范围

**Batch Normalization 的算法**：

对于一个mini-batch B = {x₁, x₂, ..., xₘ}：
$$
\mu_B = \frac{1}{m} \sum_i x_i
$$

$$
\sigma^2_B = \frac{1}{m} \sum_i (x_i - \mu_B)^2
$$

$$
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma^2_B + \varepsilon}}
$$

$$
y_i = \gamma \hat{x}_i + \beta
$$
其中：
- ε：防止除零的小常数（如1e-5）
- γ、β：可学习的参数，允许网络学习最佳的分布

**BN 的四个步骤**：

1. **计算均值和方差**：统计mini-batch的分布
2. **标准化**：均值0，方差1
3. **缩放和平移**：恢复网络的表达能力
4. **应用到每个特征维度**：独立标准化

**为什么需要 γ 和 β**：

- 标准化可能破坏网络学到的特征
- γ 和 β 让网络可以学习"撤销"标准化
- 如果 γ = √(σ²_B + ε)，β = μ_B，则恢复到原始输入

**BN 的位置**：

通常放在线性变换之后、激活函数之前：
```
输入 → 线性变换 → BN → 激活函数 → 下一层
```

也有人放在激活函数之后，两者各有支持者。

**Batch Normalization 的优势**：

1. **加速训练**：
   - 可以使用更大的学习率
   - 收敛速度显著提升（2-10倍）

2. **降低对初始化的敏感性**：
   - 即使权重初始化不好也能正常训练
   - 减少了调参难度

3. **正则化效果**：
   - 每个mini-batch的均值和方差有随机性
   - 相当于给网络引入了噪声
   - 有类似Dropout的正则化作用

4. **缓解梯度消失**：
   - 保持激活值在合理范围
   - 梯度更稳定

**BN 的缺点**：

1. **依赖batch size**：
   - batch size 太小时，统计量不准确
   - 通常需要 batch size ≥ 32

2. **训练和推理不一致**：
   - 训练时使用mini-batch统计
   - 推理时使用全局统计（移动平均）

3. **不适合序列模型**：
   - RNN等序列模型中效果不好
   - 序列长度不同导致统计困难

**推理时的 BN**：

训练时：使用当前mini-batch的均值和方差
推理时：使用训练过程中累积的全局均值和方差（指数移动平均）

**实践建议**：
- 在卷积层和全连接层后使用BN
- 可以省略Dropout（BN已有正则化效果）
- 注意batch size不要太小

### 4.4.2 权值衰减

**权值衰减（Weight Decay）**：

权值衰减是最经典的正则化方法，通过惩罚过大的权重来防止过拟合。

**基本思想**：
- 在损失函数中添加权重的惩罚项
- 鼓励权重保持较小的值
- 限制模型复杂度

**L2 正则化（最常用）**：

损失函数变为：
$$
L_{total} = L_{data} + \frac{\lambda}{2} \times \sum W^2
$$
其中：
- L_data：原始损失（如交叉熵）
- λ：正则化系数（如0.01、0.001）
- Σ W²：所有权重的平方和

权重更新规则：
$$
W \leftarrow W - \eta \times \left(\frac{\partial L_{data}}{\partial W} + \lambda W\right)
$$

$$
= (1 - \eta\lambda)W - \eta \times \frac{\partial L_{data}}{\partial W}
$$
因为有 (1 - ηλ) 这个衰减因子，所以叫权值衰减。

**L1 正则化**：

损失函数变为：
$$
L_{total} = L_{data} + \lambda \times \sum |W|
$$
**L1 vs L2 正则化**：

| 特性 | L1 | L2 |
|-----|----|----|
| 惩罚项 | |W| | W² |
| 导数 | sign(W) | W |
| 效果 | 稀疏性（很多权重变为0） | 权重均匀缩小 |
| 应用 | 特征选择 | 一般正则化 |

**为什么权值衰减能防止过拟合**：

1. **限制模型复杂度**：
   - 权重过大会被惩罚
   - 模型倾向于使用更简单的函数

2. **减少参数有效数量**：
   - 很多权重变得很小或为0
   - 相当于减少了有效参数

3. **提高泛化能力**：
   - 避免过度拟合训练数据的噪声
   - 学习更一般的模式

**λ 的选择**：

| λ 大小 | 效果 | 适用场景 |
|-------|------|---------|
| 0 | 无正则化 | 数据充足 |
| 0.0001 | 轻微正则化 | 轻微过拟合 |
| 0.001 | 中等正则化 | 一般情况 |
| 0.01 | 强正则化 | 严重过拟合 |
| 0.1 | 过强 | 可能欠拟合 |

**实践建议**：
- 默认从 λ = 0.0001 或 0.001 开始
- 通过交叉验证选择最佳值
- 注意：通常不对偏置项进行正则化

### 4.4.3 Dropout随机失活

**Dropout** 是一种非常有效的正则化技术，通过随机"丢弃"神经元来防止过拟合。

**核心思想**：
- 训练时：以概率 p 随机将神经元的输出置为0
- 测试时：使用所有神经元，但输出乘以 (1-p)

**Dropout 的工作原理**：

训练阶段（每次前向传播）：
$$
mask = np.random.rand(*x.shape) > dropout\_rate
$$

$$
x = x \times mask / (1 - dropout\_rate)
$$

测试阶段：
```
x = x  # 不做任何操作（训练时已经做了缩放）
```

**为什么 Dropout 有效**：

1. **集成学习的效果**：
   - 每次训练相当于训练一个不同的子网络
   - 最终模型是多个子网络的集成
   - 类似于随机森林

2. **减少神经元之间的依赖**：
   - 强制每个神经元学习独立的特征
   - 不能过度依赖某些神经元
   - 增强鲁棒性

3. **近似贝叶斯推断**：
   - 从理论上可以解释为近似贝叶斯推断
   - 对模型不确定性建模

**Dropout 率的选择**：

| 层类型 | 推荐 Dropout 率 | 原因 |
|-------|---------------|------|
| 输入层 | 0.1 - 0.2 | 输入信息重要，丢弃要少 |
| 隐藏层 | 0.5 | 经验值，效果最好 |
| 输出层 | 0（不使用） | 不影响最终输出 |

**Dropout 的优势**：

1. **强大的正则化效果**：
   - 显著减少过拟合
   - 在深度网络中效果显著

2. **简单易实现**：
   - 只需几行代码
   - 不增加计算复杂度（训练时）

3. **与其他技术兼容**：
   - 可以与权值衰减等技术结合
   - 进一步提升效果

**Dropout 的缺点**：

1. **延长训练时间**：
   - 需要更多的训练轮次
   - 因为每次只训练部分网络

2. **不适合所有场景**：
   - 在小数据集上可能过于激进
   - 在卷积层中不如在全连接层有效

3. **与 Batch Normalization 冲突**：
   - 同时使用时效果可能不如单独使用

**Inverted Dropout（反向Dropout）**：

现代实现通常采用 Inverted Dropout：
```
# 训练时
mask = np.random.rand(*x.shape) > dropout_rate
x = x * mask / (1 - dropout_rate)  # 训练时缩放

# 测试时
x = x  # 不做任何操作
```

优点：测试时不需要缩放，更高效。

**使用建议**：

1. **何时使用**：
   - 全连接层过拟合严重时
   - 网络参数很多时
   - 训练数据不足时

2. **何时不用**：
   - 已经使用 Batch Normalization
   - 数据量非常充足
   - 网络本身很小

3. **最佳实践**：
   - 在全连接层使用 Dropout (0.5)
   - 卷积层可以使用较小的 Dropout (0.1-0.2)
   - 与权值衰减结合使用

**Dropout 的变体**：

1. **DropConnect**：随机丢弃连接而非神经元
2. **Spatial Dropout**：在卷积层中，丢弃整个特征图
3. **Cutout**：在图像上随机遮挡区域
4. **DropBlock**：丢弃连续的区域块

---

## 本章小结

### 核心概念回顾

1. **深度网络的挑战**：
   - 梯度消失：梯度逐层衰减，前面层无法学习
   - 梯度爆炸：梯度逐层放大，训练不稳定

2. **优化算法**：
   - SGD：简单但有缺陷
   - Momentum：加速收敛，减少振荡
   - AdaGrad：自适应学习率，适合稀疏数据
   - RMSProp：解决 AdaGrad 学习率衰减问题
   - Adam：集大成者，最常用

3. **权重初始化**：
   - 不能全零初始化（对称性问题）
   - Xavier：适合 Sigmoid/Tanh
   - He：适合 ReLU（现代网络标配）

4. **正则化技术**：
   - Batch Normalization：标准化激活值，加速训练
   - 权值衰减（L2正则化）：惩罚大权重
   - Dropout：随机丢弃神经元，防止过拟合

### 实践指南

**训练深度网络的标准配置**：

```
激活函数：ReLU
权重初始化：He 初始化
优化器：Adam (学习率 0.001)
正则化：Batch Normalization + Dropout(0.5)
学习率调度：余弦退火或阶段衰减
```

**调参优先级**：

1. **首先调整**：
   - 学习率（影响最大）
   - Batch Size
   - 优化器选择

2. **其次调整**：
   - 正则化强度（dropout率、weight decay）
   - 网络结构

3. **最后调整**：
   - 学习率调度策略
   - 其他超参数

**常见问题排查**：

| 问题 | 可能原因 | 解决方案 |
|-----|---------|---------|
| 损失不下降 | 学习率过小 | 增大学习率 |
| 损失震荡 | 学习率过大 | 减小学习率 |
| 训练损失低但测试损失高 | 过拟合 | 增加正则化 |
| 训练和测试损失都高 | 欠拟合 | 增大网络容量 |
| 损失变为NaN | 梯度爆炸 | 减小学习率，检查初始化 |

### 关键收获

✅ 理解深度网络的训练难点及解决方案  
✅ 掌握各种优化算法的原理和应用场景  
✅ 理解权重初始化的重要性  
✅ 掌握 Batch Normalization、Dropout 等正则化技术  
✅ 能够为具体问题选择合适的训练策略  

### 后续学习方向

在掌握本章的训练技巧后，可以深入学习：

1. **高级优化技术**：
   - 学习率预热（Warmup）
   - 梯度裁剪（Gradient Clipping）
   - 混合精度训练

2. **正则化的变体**：
   - Layer Normalization
   - Group Normalization
   - DropBlock

3. **架构创新**：
   - 残差连接（ResNet）
   - 注意力机制
   - Transformer

4. **自动机器学习**：
   - 超参数自动搜索
   - 神经架构搜索（NAS）

这些训练技巧是现代深度学习成功的关键，通过结合理论学习和实际编码实践，您将能够训练出高性能的深度神经网络。

---

**最后更新**：2026年1月30日
